{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f9d55e2cd5792dc66d332ef3ccafde266046ce4",
    "colab_type": "text",
    "id": "uOcS5s3VZKFq"
   },
   "source": [
    "The German Credit data set is a publically available data set downloaded from the UCI Machine Learning Repository. The data contains data on 20 variables and the classification whether an applicant is considered a Good or a Bad credit risk for 1000 loan applicants.\n",
    "\n",
    "### [Data Source](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data))\n",
    "- Professor Dr. Hans Hofmann  \n",
    "- Institut f\"ur Statistik und \"Okonometrie  \n",
    "- Universit\"at Hamburg  \n",
    "- FB Wirtschaftswissenschaften  \n",
    "- Von-Melle-Park 5    \n",
    "- 2000 Hamburg 13\n",
    "\n",
    "### Benchmark\n",
    "![Credit Risk Classification: Faster Machine Learning with Intel Optimized Packages](https://i.imgur.com/nL1l7WI.png)\n",
    "\n",
    "according to [1] the best model is Random Forest with balanced feature selection data. it's has Accuracy 82%, Precision 84%, Recall 82% and F1-Score 81%. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "The goal of this kernel is to beat The benchmark with  :\n",
    "- Convert dataset to Machine Learning friendly (Feature Engginering)\n",
    "- Develop XGBoost model to predict whether a loan is a good or bad risk.\n",
    "- Find the Best parameter for XGBoost Model (Hyperparameter Tunning)\n",
    "- Beat the Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "12bfcccb8223f3c0039be46a701bff6b3311eb74",
    "colab_type": "text",
    "id": "BFIDjGe8BNiZ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63a5648103f48c821752a5b1f403dfb477159180",
    "colab_type": "text",
    "id": "kqRSZpTCfG10"
   },
   "source": [
    "# Table of Content\n",
    "\n",
    "**1. [Introduction](#Introduction)** <br>\n",
    "    - Import Library\n",
    "    - Evaluation Function\n",
    "    - XGBoost Model\n",
    "**2. [Preprocess](#Preprocess)** <br>\n",
    "    - Importing Dataset\n",
    "    - StandardScaler\n",
    "    - Encoding Categorical Feature\n",
    "    - Concate Transformed Dataset\n",
    "    - Split Training Dataset\n",
    "    - XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)\n",
    "    - XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)\n",
    "**3. [Balanced Dataset](#Balanced Dataset)** <br>    \n",
    "    - XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)\n",
    "    - **XGBoost 2b: Balanced (ROC_AUC:0.80)**\n",
    "**4. [Others](#Others)** <br>  \n",
    "    - Lighgbm (ROC_AUC:0.73)\n",
    "    - LogisticRegression (ROC_AUC:0.77)\n",
    "    - RandomForestClassifier (ROC_AUC:0.69)\n",
    "    - ExtraTreesClassifier (ROC_AUC:0.74)\n",
    "    - DecisionTreeClassifier (ROC_AUC:0.64)\n",
    "    - GradientBoostingClassifier (ROC_AUC:0.76)\n",
    "    - AdaBoostClassifier (ROC_AUC:0.72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "afe3100b12ba5779b15f698a1975eaab170742c4",
    "colab_type": "text",
    "id": "BwWgAWVLC2Ln"
   },
   "source": [
    "<a id=\"Introduction\"></a> <br>\n",
    "# **1. Introduction:** \n",
    "- Import Library\n",
    "- Evaluation Function\n",
    "- XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86c6a56e4b0988d902401370b957f63f4f2754f1",
    "colab_type": "text",
    "id": "oZH67UWnA915"
   },
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "fa1b3ac82eb8fe1b02d69fab3a10b621f1392484",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UQUQbCn-LIjR"
   },
   "outputs": [],
   "source": [
    "#Importing necessary packages in Python \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import numpy as np ; np.random.seed(sum(map(ord, \"aesthetics\")))\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification \n",
    "#from sklearn.learning_curve import learning_curve \n",
    "#from sklearn.cross_validation import train_test_split \n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit,train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize, StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn \n",
    "seaborn.set_context('notebook') \n",
    "seaborn.set_style(style='darkgrid')\n",
    "\n",
    "from pprint import pprint \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "import matplotlib.patches as patches\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "#from packages import *\n",
    "#from ml_fairness import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e53977fea8ba2969bb815820b810ae0798f79ff3",
    "colab_type": "text",
    "id": "HvfBj0KiBC1m"
   },
   "source": [
    "### Evaluation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ad532098b4568aab69e710aa1b73097b0aeaa56a",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Y5FAGSW_K_il"
   },
   "outputs": [],
   "source": [
    "# Function for evaluation reports\n",
    "def get_eval1(clf, X,y):\n",
    "    # Cross Validation to test and anticipate overfitting problem\n",
    "    scores1 = cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "    scores2 = cross_val_score(clf, X, y, cv=2, scoring='precision')\n",
    "    scores3 = cross_val_score(clf, X, y, cv=2, scoring='recall')\n",
    "    scores4 = cross_val_score(clf, X, y, cv=2, scoring='roc_auc')\n",
    "    \n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n",
    "    \n",
    "    return \n",
    "\n",
    "def get_eval2(clf, X_train, y_train,X_test, y_test):\n",
    "    # Cross Validation to test and anticipate overfitting problem\n",
    "    scores1 = cross_val_score(clf, X_test, y_test, cv=2, scoring='accuracy')\n",
    "    scores2 = cross_val_score(clf, X_test, y_test, cv=2, scoring='precision')\n",
    "    scores3 = cross_val_score(clf, X_test, y_test, cv=2, scoring='recall')\n",
    "    scores4 = cross_val_score(clf, X_test, y_test, cv=2, scoring='roc_auc')\n",
    "    \n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n",
    "    \n",
    "    return  \n",
    "  \n",
    "# Function to get roc curve\n",
    "def get_roc (y_test,y_pred):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #Plot of a ROC curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "148a2b3cfebaac7674b5bb78496d1cf0266a26cf",
    "colab_type": "text",
    "id": "ktQtae8aBGPQ"
   },
   "source": [
    "#### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a7b80d642ccc18e23b9a0ece9c7f57eca3c67cfd",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qOM2Y0A8CGN8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "#print('XGBoost v',xgb.__version__)\n",
    "\n",
    "# fit, train and cross validate Decision Tree with training and test data \n",
    "def xgbclf(params, X_train, y_train,X_test, y_test):\n",
    "  \n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)]\n",
    "    \n",
    "    model = XGBClassifier(**params).\\\n",
    "      fit(X_train, y_train, eval_set=eval_set, \\\n",
    "                  eval_metric='auc', early_stopping_rounds = 100, verbose=100)\n",
    "        \n",
    "    #print(model.best_ntree_limit)\n",
    "\n",
    "    model.set_params(**{'n_estimators': model.best_ntree_limit})\n",
    "    model.fit(X_train, y_train)\n",
    "    #print(model,'\\n')\n",
    "    \n",
    "    # Predict target variables y for test data\n",
    "    y_pred = model.predict(X_test, ntree_limit=model.best_ntree_limit) #model.best_iteration\n",
    "    #print(y_pred)\n",
    "   \n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(model, X_train, y_train)\n",
    "    #get_eval2(model, X_train, y_train,X_test, y_test)\n",
    "    \n",
    "    # Create and print confusion matrix    \n",
    "    abclf_cm = confusion_matrix(y_test,y_pred)\n",
    "    print(abclf_cm)\n",
    "    \n",
    "    #y_pred = model.predict(X_test)\n",
    "    print (classification_report(y_test,y_pred) )\n",
    "    print ('\\n')\n",
    "    print (\"Model Final Generalization Accuracy: %.6f\" %accuracy_score(y_test,y_pred) )\n",
    "    \n",
    "    # Predict probabilities target variables y for test data\n",
    "    y_pred_proba = model.predict_proba(X_test, ntree_limit=model.best_ntree_limit)[:,1] #model.best_iteration\n",
    "    get_roc (y_test,y_pred_proba)\n",
    "    return model\n",
    "\n",
    "def plot_featureImportance(model, keys):\n",
    "  importances = model.feature_importances_\n",
    "\n",
    "  importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(keys)})\n",
    "  importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "  importance_frame.tail(10).plot(kind = 'barh', x = 'Feature', figsize = (8,8), color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e8d5ce5e9daf39d851ca53856f640a90156745a",
    "colab_type": "text",
    "id": "b9VmiiUDCvRV"
   },
   "source": [
    "<a id=\"Preprocess\"></a> <br>\n",
    "# **2. Preprocess** \n",
    "- Importing Dataset\n",
    "- StandardScaler\n",
    "- Encoding Categorical Feature\n",
    "- Concate Transformed Dataset\n",
    "- Split Training Dataset\n",
    "- XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)\n",
    "- XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "366cfb21b371f12c5bbf005342de219717fde974",
    "colab_type": "text",
    "id": "L4G0iMwfKb4J"
   },
   "source": [
    "### Import Dataset\n",
    "\n",
    "OK let's get started. We'll download the data from the UCI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4807a2a54ddeb7ecb9142b586088ea672103d4ff",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1531200575113,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "YYgBTbPj1fbQ",
    "outputId": "d5569d76-1c4f-432a-a2b7-2b9ceb3e3439"
   },
   "outputs": [],
   "source": [
    "file = '../../Data/german-credit.csv'\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "\n",
    "names = ['existingchecking', 'duration', 'credithistory', 'purpose', 'creditamount', \n",
    "         'savings', 'employmentsince', 'installmentrate', 'statussex', 'otherdebtors', \n",
    "         'residencesince', 'property', 'age', 'otherinstallmentplans', 'housing', \n",
    "         'existingcredits', 'job', 'peopleliable', 'telephone', 'foreignworker', 'classification']\n",
    "\n",
    "data = pd.read_csv(file,names = names, delimiter=' ')\n",
    "print(data.shape)\n",
    "print (data.columns)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "224c2c3967abdccd1e4527c18024e08288ba1ca9",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1531189108051,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "B3FPJfz33xkK",
    "outputId": "9c678580-fb5a-4f2c-a788-676f3fda2d60"
   },
   "outputs": [],
   "source": [
    "# Binarize the y output for easier use of e.g. ROC curves -> 0 = 'bad' credit; 1 = 'good' credit\n",
    "data.classification.replace([1,2], [1,0], inplace=True)\n",
    "# Print number of 'good' credits (should be 700) and 'bad credits (should be 300)\n",
    "data.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d2774790c3f63cfc0eaa81517ce8f0eb4680478",
    "colab_type": "text",
    "id": "Tr1A8ZIHzuFw"
   },
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f03a76714ee08fe41f9b59aab287d68d481892b5",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dKKUEqTo380x"
   },
   "outputs": [],
   "source": [
    "#numerical variables labels\n",
    "numvars = ['creditamount', 'duration', 'installmentrate', 'residencesince', 'age', \n",
    "           'existingcredits', 'peopleliable', 'classification']\n",
    "\n",
    "# Standardization\n",
    "numdata_std = pd.DataFrame(StandardScaler().fit_transform(data[numvars].drop(['classification'], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19dce81fc16194265c5d8942fa81c64934d60855",
    "colab_type": "text",
    "id": "X4ZzfmRy4M9I"
   },
   "source": [
    "### Encoding Categorical Feature\n",
    "\n",
    "Labelencoding to transform categorical to numerical, Enables better Visualization than one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dab67695a0984af965a7dbea250276c4369b5875",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1531189110846,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "xSnUU8E_4IgX",
    "outputId": "4325e306-c15b-4130-ee8b-105729ccd053"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#categorical variables labels\n",
    "catvars = ['existingchecking', 'credithistory', 'purpose', 'savings', 'employmentsince',\n",
    "           'statussex', 'otherdebtors', 'property', 'otherinstallmentplans', 'housing', 'job', \n",
    "           'telephone', 'foreignworker']\n",
    "\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "# Encoding the variable\n",
    "lecatdata = data[catvars].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# print transformations\n",
    "for x in range(len(catvars)):\n",
    "    print(catvars[x],\": \", data[catvars[x]].unique())\n",
    "    print(catvars[x],\": \", lecatdata[catvars[x]].unique())\n",
    "\n",
    "#One hot encoding, create dummy variables for every category of every categorical variable\n",
    "dummyvars = pd.get_dummies(data[catvars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a15498bdd45a6b2d0c88edbe3059744294396c6",
    "colab_type": "text",
    "id": "R3OBrifU4Zpb"
   },
   "source": [
    "### Concate Transformed Dataset\n",
    "append the dummy variable of the initial numerical variables numvars# append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50738e0e4b89a8facc7c73581661f3110427d8e9",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1531189111653,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "jkncbC1M4ZzD",
    "outputId": "4b596160-48a6-40c5-8fd2-2104e3afabe9"
   },
   "outputs": [],
   "source": [
    "data_clean = pd.concat([data[numvars], dummyvars], axis = 1)\n",
    "\n",
    "print(data_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53f8db9397eeb56dae3d735e712b4ba251a36a7b",
    "colab_type": "text",
    "id": "OI89YwDN4kXI"
   },
   "source": [
    "### Split Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f1724b5dc93f592481eb1c608553d1c5fad2108",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cP6puz7s4hQr"
   },
   "outputs": [],
   "source": [
    "# Unscaled, unnormalized data\n",
    "X_clean = data_clean.drop('classification', axis=1)\n",
    "y_clean = data_clean['classification']\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean,y_clean,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "900557195bd519524bb3d46fb6b3d8d7344692dc",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1531189113358,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "MkEfVz7rgssR",
    "outputId": "2545c4f2-9d69-4d50-dc1c-82525586f013"
   },
   "outputs": [],
   "source": [
    "X_train_clean.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "924ad3aaf8f771939fafab52352598b158d4d9bb",
    "colab_type": "text",
    "id": "3LRHY79JAlbF"
   },
   "source": [
    "### XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03740b4aa1ec34f7874001fe00f36496a607050b",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1039
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1831,
     "status": "ok",
     "timestamp": 1531192485583,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "trS6OdaaEoKL",
    "outputId": "38c94f83-752e-4e6d-8439-b42692b6f9f1"
   },
   "outputs": [],
   "source": [
    "params={}\n",
    "xgbclf(params, X_train_clean, y_train_clean, X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10ebb57456ac4233b77b1ad284c15984aee73a1c"
   },
   "source": [
    "### XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b27e5641d57347d244ebc33a634c35a3a8e0947",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={}\n",
    "\n",
    "params1={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.05,\n",
    "    'gamma':0.1,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.3,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':3,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "params2={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.005,\n",
    "    #'gamma':0.01,\n",
    "    'subsample':0.555,\n",
    "    'colsample_bytree':0.7,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':8,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "xgbclf(params2, X_train_clean, y_train_clean, X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b14d322c24858a4b4ec4656bd96eb3a1843802e1",
    "colab_type": "text",
    "id": "bFxEnRYVD_Xe"
   },
   "source": [
    "<a id=\"Balanced Dataset\"></a> <br>\n",
    "# **3. Balanced Dataset** \n",
    "- XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)\n",
    "- XGBoost 2b: Balanced (ROC_AUC:0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfba5a9de83536e8ee9635d98339dfd33b7d657a",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1531189121767,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "5NEgnXdM1U0J",
    "outputId": "d3404eb4-ed88-46ea-ab18-60b259a22ed2"
   },
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Oversampling\n",
    "# http://contrib.scikit-learn.org/imbalanced-learn/auto_examples/combine/plot_smote_enn.html#sphx-glr-auto-examples-combine-plot-smote-enn-py\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(ratio='auto')\n",
    "X_train_clean_res, y_train_clean_res = sm.fit_sample(X_train_clean, y_train_clean)\n",
    "\n",
    "# Print number of 'good' credits and 'bad credits, should be fairly balanced now\n",
    "print(\"Before/After clean\")\n",
    "unique, counts = np.unique(y_train_clean, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(y_train_clean_res, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8a7a3c79685af31aecb2ade360415f92a30460b",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "h2-muneU1U9H"
   },
   "outputs": [],
   "source": [
    "#Great, before we do anything else, let's split the data into train/test.\n",
    "X_train_clean_res = pd.DataFrame(X_train_clean_res, columns=X_train_clean.keys())\n",
    "#y_train_clean_res = pd.DataFrame(y_train_clean_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a8b147901159dc4ac09fa2efd4d5d9578f97b99",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1531189123494,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "C-yIxVQkUZyW",
    "outputId": "ae623e97-04e8-4417-8311-3da47f9b94e3"
   },
   "outputs": [],
   "source": [
    "print(np.shape(X_train_clean_res))\n",
    "print(np.shape(y_train_clean_res))\n",
    "print(np.shape(X_test_clean)) \n",
    "print(np.shape(y_test_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04626b0c29b5a77a013fedfee30b55b4d92b684b"
   },
   "source": [
    "### XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca524e248c28f147289605a30f68b11ecabe4559",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1321,
     "status": "ok",
     "timestamp": 1531189328790,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "NQ5P5oG0IwIS",
    "outputId": "3f402469-f7d9-496d-e772-059ef4ef0aec"
   },
   "outputs": [],
   "source": [
    "#BASE MODEL\n",
    "params={}\n",
    "xgbclf(params,X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71a3040a7d73bfa3aba166e10d804f9257d8bde8",
    "colab_type": "text",
    "id": "RjlSw9En1P4p"
   },
   "source": [
    "### XGBoost 2b: Balanced (ROC_AUC:0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11855f908fb13b97d120ea375c75ab13885d9e43",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1403
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1531192901612,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "x9PHpLlJoNFz",
    "outputId": "ed2910d2-4508-49d9-d1be-575c07625fb6"
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params1={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.05,\n",
    "    'gamma':0.1,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.3,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':3,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "params2={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.005,\n",
    "    #'gamma':0.01,\n",
    "    'subsample':0.555,\n",
    "    'colsample_bytree':0.7,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':8,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "#xgbclf(params, X_train, y_train,X_test,y_test)\n",
    "model = xgbclf(params2,X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)\n",
    "model\n",
    "#plot_featureImportance(model, X_train_clean_res.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "518227609cbeb12fa67390bd5a097ddc7bd2f71a",
    "colab_type": "text",
    "id": "T0uGUXyUa4h_"
   },
   "source": [
    "# 4.  Feature Selection\n",
    "- XGBoost3 (Base Model:ROC_AUC:0.73)\n",
    "- GridSearchCV (ROC_AUC:0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9da497ba8de093a285cf4ffbec4535219c74466",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vOISYxySN4qJ"
   },
   "outputs": [],
   "source": [
    "#model = xgbclf(params1,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(X_train_clean_res.keys())})\n",
    "importance_frame.sort_values(by = 'Importance', inplace = True, ascending=False)\n",
    "importance_col = importance_frame.Feature.head(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a2ce51442a79c7a28776f90153e4107737183abd"
   },
   "source": [
    "### XGBoost3 (Base Model:ROC_AUC:0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17ef3ab68a22b1af2a31b58e0a452a72e0db19bd",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1056
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1923,
     "status": "ok",
     "timestamp": 1531195815598,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "LwqK7dpAX7nn",
    "outputId": "e4689e0c-52b0-476a-b84c-e47da4028a37"
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params1={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.01,\n",
    "    #'gamma':0.1,\n",
    "    #'subsample':0.8,\n",
    "    #'colsample_bytree':0.3,\n",
    "    #'min_child_weight':3,\n",
    "    'max_depth':3,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "xgbclf(params,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8037e33ee37292b23413304ceff57026c6b49e1",
    "colab_type": "text",
    "id": "Wxgbu6HbrstB"
   },
   "source": [
    "### GridSearchCV (ROC_AUC:0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "105346b26c0fe9e4cba1b68b6194be9d70b50701",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3066,
     "status": "ok",
     "timestamp": 1531196561870,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "m7lf_As9oUvh",
    "outputId": "6ff51851-0fe9-4c53-c5cf-315fa84143e4"
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "print('XGBoost with grid search')\n",
    "# play with these params\n",
    "params={\n",
    "    'learning_rate': [0.01, 0.02],\n",
    "    'max_depth': [3], # 5 is good but takes too long in kaggle env\n",
    "    #'subsample': [0.6], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    #'colsample_bytree': [0.5], #[0.5,0.6,0.7,0.8],\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500]\n",
    "    #'reg_alpha': [0.03] #[0.01, 0.02, 0.03, 0.04]\n",
    "}\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "rs = GridSearchCV(xgb_clf,\n",
    "                  params,\n",
    "                  cv=2,\n",
    "                  scoring=\"roc_auc\",\n",
    "                  n_jobs=1,\n",
    "                  verbose=False)\n",
    "rs.fit(X_train_clean_res[importance_col], y_train_clean_res)\n",
    "best_est = rs.best_estimator_\n",
    "print(best_est)\n",
    "print(rs.best_score_)\n",
    "\n",
    "# Roc AUC with test data\n",
    "print(rs.score(X_test_clean[importance_col],y_test_clean))\n",
    "\n",
    "# Roc AUC with all train data\n",
    "#y_pred_proba = best_est.predict_proba(X_test_clean[importance_col])[:,1]\n",
    "#print(\"Roc AUC: \", roc_auc_score(y_test_clean, y_pred_proba))\n",
    "\n",
    "#xgbclf(params1,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2fe0b7ea9b605569bdfa60b39faf7d6965bfde0"
   },
   "source": [
    "<a id=\"Others\"></a> <br>\n",
    "# 5. Others\n",
    "- Lighgbm (ROC_AUC:0.73)\n",
    "- LogisticRegression (ROC_AUC:0.77)\n",
    "- RandomForestClassifier (ROC_AUC:0.69)\n",
    "- ExtraTreesClassifier (ROC_AUC:0.74)\n",
    "- DecisionTreeClassifier (ROC_AUC:0.64)\n",
    "- GradientBoostingClassifier (ROC_AUC:0.76)\n",
    "- AdaBoostClassifier (ROC_AUC:0.72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "360450a8797f752a9d9b09a4c4a16d72dbe0b071",
    "colab_type": "text",
    "id": "Pce2PcrQryuY"
   },
   "source": [
    "### Lighgbm (ROC_AUC:0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "432aa50546f660ed1ae9b4ab064bbea7b6f54e03",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# fit, train and cross validate Decision Tree with training and test data \n",
    "def lgbclf(X_train, y_train,X_test, y_test):\n",
    "\n",
    "    model = lgb.LGBMClassifier().fit(X_train, y_train)\n",
    "    print(model,'\\n')\n",
    "\n",
    "    # Predict target variables y for test data\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(model, X_train, y_train,y_test,y_pred)\n",
    "    #get_eval2(model, X_train, y_train,X_test, y_test,y_pred)\n",
    "    get_roc (y_test,y_pred)\n",
    "    return\n",
    "\n",
    "# Logistic Regression\n",
    "#lgbclf(X_train, y_train,X_test,y_test)\n",
    "lgbclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "318b9364794e6f1e2da5550bf961885bdccc5825",
    "colab_type": "text",
    "id": "tzhgWR1hry3s"
   },
   "source": [
    "### LogisticRegression (ROC_AUC:0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0b612a0bab5b2f06e038f37b35868716f97bd00",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit, train and cross validate Decision Tree with training and test data \n",
    "def logregclf(X_train, y_train,X_test, y_test):\n",
    "    print(\"LogisticRegression\")\n",
    "    model = LogisticRegression().fit(X_train, y_train)\n",
    "    print(model,'\\n')\n",
    "\n",
    "    # Predict target variables y for test data\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(model, X_train, y_train,y_test,y_pred)\n",
    "    #get_eval2(model, X_train, y_train,X_test, y_test,y_pred)\n",
    "    get_roc (y_test,y_pred)\n",
    "    return\n",
    "\n",
    "# Logistic Regression\n",
    "#logregclf(X_train, y_train,X_test,y_test)\n",
    "logregclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e95e51b587054a97daf75be89cd308b615feb8ca"
   },
   "source": [
    "### RandomForestClassifier (ROC_AUC:0.69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b9f601bd07ff3253da4d89352ebd785fc3eeac2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# fit, train and cross validate Decision Tree with training and test data \n",
    "def randomforestclf(X_train, y_train,X_test, y_test):\n",
    "    print(\"RandomForestClassifier\")\n",
    "    randomforest = RandomForestClassifier().fit(X_train, y_train)\n",
    "    print(randomforest,'\\n')\n",
    "    \n",
    "    # Predict target variables y for test data\n",
    "    y_pred = randomforest.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(randomforest, X_train, y_train,y_test,y_pred)\n",
    "    get_roc (y_test,y_pred)\n",
    "    return\n",
    "\n",
    "# Random Forest\n",
    "# Choose clean data, as tree is robust\n",
    "randomforestclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "75fb46bd9b0ac1493449c6451b2f8a85974d4f86"
   },
   "source": [
    "### ExtraTreesClassifier (ROC_AUC:0.74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28df42b00dedfda6ffcfb8235ff0ad2ef42a4bec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# fit, train and cross validate Decision Tree with training and test data \n",
    "def extratreesclf(X_train, y_train,X_test, y_test):\n",
    "    print(\"ExtraTreesClassifier\")\n",
    "    extratrees = ExtraTreesClassifier().fit(X_train, y_train)\n",
    "    print(extratrees,'\\n')\n",
    "    \n",
    "    # Predict target variables y for test data\n",
    "    y_pred = extratrees.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(extratrees, X_train, y_train,y_test,y_pred)\n",
    "    \n",
    "    get_roc (y_test,y_pred)\n",
    "    return\n",
    " \n",
    "# Extra Trees\n",
    "# Choose clean data, as tree is robust\n",
    "extratreesclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d08be5c932aa326666c8865f5c1ce15f5f7984b4"
   },
   "source": [
    "### DecisionTreeClassifier (ROC_AUC:0.64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07c8334d26469b64ded21db507d7d246d0ba05f6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "# fit, train and cross validate Decision Tree with training and test data \n",
    "def dectreeclf(X_train, y_train,X_test, y_test):\n",
    "    print(\"DecisionTreeClassifier\")\n",
    "    dec_tree = DecisionTreeClassifier(min_samples_split=10,min_samples_leaf=5).fit(X_train, y_train)\n",
    "    print(dec_tree,'\\n')\n",
    "    \n",
    "    # Predict target variables y for test data\n",
    "    y_pred = dec_tree.predict_proba(X_test)[:,1]\n",
    "\n",
    "    \n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(dec_tree, X_train, y_train,y_test,y_pred)\n",
    "    get_roc (y_test,y_pred)\n",
    "    return\n",
    "\n",
    "# Decisiontree\n",
    "dectreeclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ed9e0b8545196403507dde0a878ba1a5f7cc604",
    "colab_type": "text",
    "id": "nA3tHbQDry_f"
   },
   "source": [
    "### GradientBoostingClassifier (ROC_AUC:0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72b88670afd0ba8487d1a3a98bbecde61427aa4f",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5896,
     "status": "ok",
     "timestamp": 1530921188337,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "JjxG_CYtekIA",
    "outputId": "42c5bdfd-94d2-47fd-e82b-7a9a5e664528"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# fit, train and cross validate GradientBoostingClassifier with training and test data \n",
    "def gradientboostingclf(X_train, y_train, X_test, y_test):  \n",
    "    print(\"GradientBoostingClassifier\")\n",
    "    gbclf = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "    print(gbclf,'\\n')\n",
    "    \n",
    "    # Predict target variables y for test data\n",
    "    y_pred = gbclf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(gbclf, X_train, y_train,y_test,y_pred)\n",
    "    get_roc (y_test,y_pred)\n",
    "    return\n",
    "  \n",
    "# GradientBoostingClassifier\n",
    "# Choose clean data, as tree is robust\n",
    "gradientboostingclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2d254a8b7a76f3fcd3f98277a52989c5df7d0c2"
   },
   "source": [
    "### AdaBoostClassifier (ROC_AUC:0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8caa356aa7993faa1bd77afafd858b7f95e18b8",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4970,
     "status": "ok",
     "timestamp": 1530921206830,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     },
     "user_tz": -420
    },
    "id": "wdN9GgUUetH1",
    "outputId": "127b3cf9-a597-4d63-f296-b4ceeb0d6a19"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# fit, train and cross validate GradientBoostingClassifier with training and test data \n",
    "def adaboostclf(X_train, y_train, X_test, y_test):  \n",
    "    print(\"AdaBoostClassifier\")\n",
    "    abclf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "    print(abclf,'\\n')\n",
    "    \n",
    "    # Predict target variables y for test data\n",
    "    y_pred = abclf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(abclf, X_train, y_train,y_test,y_pred)\n",
    "    get_roc (y_test,y_pred)\n",
    "    return\n",
    "\n",
    "# AdaBoostClassifier\n",
    "# Choose clean data, as tree is robust\n",
    "adaboostclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "german-credit_XGB1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
