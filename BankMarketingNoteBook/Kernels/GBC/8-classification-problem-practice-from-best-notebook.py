#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


# In[ ]:


import matplotlib.pyplot as plt
import seaborn as sns
get_ipython().run_line_magic('matplotlib', 'inline')
import warnings
warnings.filterwarnings('ignore')


# In[ ]:


data = pd.read_csv("../input/bank-marketing/bank-additional-full.csv", sep=";")


# In[ ]:


data.head()


# In[ ]:


data.columns


# In[ ]:


data.shape


# In[ ]:


data.describe()


# In[ ]:


data.info()


# In[ ]:


data['job'].value_counts()


# In[ ]:


data['y'].value_counts()


# In[ ]:


data['y'].head()


# In[ ]:


data_new = data.copy()


# In[ ]:


y = data[['y']]
x = data_new.drop('y', axis=1)


# In[ ]:


x.shape, y.shape


# In[ ]:


y.value_counts()


# In[ ]:


y = pd.get_dummies(y, drop_first=True)


# In[ ]:


y.value_counts()


# In[ ]:


for i in x.columns:
    print("This column has categories \n: ", x[i].unique())


# In[ ]:


print('Jobs:\n', x['job'].value_counts())
print('Marital Status:\n', x['marital'].value_counts())
print('Education:\n', x['education'].value_counts())
print('Default:\n', x['default'].value_counts())
print('Housing:\n', x['housing'].value_counts())
print('Loan:\n', x['loan'].value_counts())
print('Contact:\n', x['contact'].value_counts())
print('month:\n', x['month'].value_counts())
print('day_of_week:\n', x['day_of_week'].value_counts())
print('poutcome:\n', x['poutcome'].value_counts())


# In[ ]:


x.isnull().sum()
y.isnull().sum()


# In[ ]:


x.select_dtypes(include="object")


# In[ ]:


import pandas_profiling
x.profile_report()


# In[ ]:


# Label encoder order is alphabetical
from sklearn.preprocessing import LabelEncoder
labelencoder_X = LabelEncoder()
x['job']      = labelencoder_X.fit_transform(x['job']) 
x['marital']  = labelencoder_X.fit_transform(x['marital']) 
x['education']= labelencoder_X.fit_transform(x['education']) 
x['default']  = labelencoder_X.fit_transform(x['default']) 
x['housing']  = labelencoder_X.fit_transform(x['housing']) 
x['contact']  = labelencoder_X.fit_transform(x['contact'])
x['month']     = labelencoder_X.fit_transform(x['month'])
x['day_of_week'] = labelencoder_X.fit_transform(x['day_of_week'])


# In[ ]:


fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))
sns.boxplot(x = 'duration', data = x, orient = 'v', ax = ax1)
ax1.set_xlabel('Calls', fontsize=10)
ax1.set_ylabel('Duration', fontsize=10)
ax1.set_title('Calls Distribution', fontsize=10)
ax1.tick_params(labelsize=10)

sns.distplot(x['duration'], ax = ax2)
sns.despine(ax = ax2)
ax2.set_xlabel('Duration Calls', fontsize=10)
ax2.set_ylabel('Occurence', fontsize=10)
ax2.set_title('Duration x Ocucurence', fontsize=10)
ax2.tick_params(labelsize=10)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()


# In[ ]:


print('1ยบ Quartile: ', x['duration'].quantile(q = 0.25))
print('2ยบ Quartile: ', x['duration'].quantile(q = 0.50))
print('3ยบ Quartile: ', x['duration'].quantile(q = 0.75))
print('4ยบ Quartile: ', x['duration'].quantile(q = 1.00))
print('Duration calls above: ', x['duration'].quantile(q = 0.75) + 
                      1.5*(x['duration'].quantile(q = 0.75) - x['duration'].quantile(q = 0.25)), 'are outliers')


# In[ ]:


print('Numerber of outliers: ', x[x['duration'] > 644.5]['duration'].count())
print('Number of clients: ', len(x))
#Outliers in %
print('Outliers are:', round(x[x['duration'] > 644.5]['duration'].count()*100/len(x),2), '%')


# In[ ]:


x['poutcome'].replace(['nonexistent', 'failure', 'success'], [1,2,3], inplace  = True)


# In[ ]:


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 1)
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, accuracy_score
k_fold = KFold(n_splits=10, shuffle=True, random_state=0)


# In[ ]:


x_train.shape, x_test.shape, y_train.shape, y_test.shape


# In[ ]:


x_train.head()


# In[ ]:


from sklearn.preprocessing import StandardScaler
scale = StandardScaler()
x_train = scale.fit_transform(x_train)
x_test = scale.fit_transform(x_test)


# In[ ]:


from sklearn import model_selection
from sklearn.neighbors import KNeighborsClassifier


# In[ ]:


neighbors = np.arange(0,25)


# In[ ]:


cv_scores = []


# In[ ]:


for k in neighbors:
    k_value = k+1
    knn = KNeighborsClassifier(n_neighbors = k_value, weights='uniform', p=2, metric='euclidean')
    kfold = model_selection.KFold(n_splits=10, random_state=123)
    scores = model_selection.cross_val_score(knn, x_train, y_train, cv=kfold, scoring='accuracy')
    cv_scores.append(scores.mean()*100)
    print("k=%d %0.2f (+/- %0.2f)" % (k_value, scores.mean()*100, scores.std()*100))

optimal_k = neighbors[cv_scores.index(max(cv_scores))]
print ("The optimal number of neighbors is %d with %0.1f%%" % (optimal_k, cv_scores[optimal_k]))

plt.plot(neighbors, cv_scores)
plt.xlabel('Number of Neighbors K')
plt.ylabel('Train Accuracy')
plt.show()


# In[ ]:


from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=22)
knn.fit(x_train, y_train)


# In[ ]:


knnpred = knn.predict(x_test)


# In[ ]:


print(confusion_matrix(y_test, knnpred))


# In[ ]:


print(round(accuracy_score(y_test, knnpred),2)*100)


# In[ ]:


KNNCV = (cross_val_score(knn, x_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())


# In[ ]:


KNNCV


# In[ ]:


from sklearn.svm import SVC
svc= SVC(kernel = 'sigmoid')
svc.fit(x_train, y_train)
svcpred = svc.predict(x_test)
print(confusion_matrix(y_test, svcpred))
print(round(accuracy_score(y_test, svcpred),2)*100)
SVCCV = (cross_val_score(svc, x_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())


# In[ ]:


from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini
dt.fit(x_train, y_train)
pred = dt.predict(x_test)

print(confusion_matrix(y_test, pred))
print(round(accuracy_score(y_test, pred),2)*100)
DTREECV = (cross_val_score(dt, x_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())


# In[ ]:


from sklearn.linear_model import LogisticRegression
logmodel = LogisticRegression() 
logmodel.fit(x_train,y_train)
logpred = logmodel.predict(x_test)


print(confusion_matrix(y_test, logpred))
print(round(accuracy_score(y_test, logpred),2)*100)
LOGCV = (cross_val_score(logmodel, x_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())


# In[ ]:


from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators = 200)#criterion = entopy,gini
rfc.fit(x_train, y_train)
rfcpred = rfc.predict(x_test)

print(confusion_matrix(y_test, rfcpred ))
print(round(accuracy_score(y_test, rfcpred),2)*100)
RFCCV = (cross_val_score(rfc, x_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())


# In[ ]:


from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(x_train, y_train)
xgbprd = xgb.predict(x_test)

print(confusion_matrix(y_test, xgbprd ))
print(round(accuracy_score(y_test, xgbprd),2)*100)
XGB = (cross_val_score(estimator = xgb, X=x_train, y=y_train, cv = 10).mean())


# In[ ]:


from sklearn.ensemble import GradientBoostingClassifier
gbk = GradientBoostingClassifier()
gbk.fit(x_train, y_train)
gbkpred = gbk.predict(x_test)
print(confusion_matrix(y_test, gbkpred ))
print(round(accuracy_score(y_test, gbkpred),2)*100)
GBKCV = (cross_val_score(gbk, x_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())


# In[ ]:


models = pd.DataFrame({'Models': ['Random Forest Classifier', 'Decision Tree Classifier', 'Support Vector Machine',
                           'K-Near Neighbors', 'Logistic Model', 'XGBoost', 'Gradient Boosting'],
                'Score':  [RFCCV, DTREECV, SVCCV, KNNCV, LOGCV, XGB, GBKCV]})
models.sort_values(by='Score', ascending=False)


# In[ ]:


from sklearn import metrics
fig, (ax, ax1) = plt.subplots(nrows = 2, ncols = 2, figsize = (15,5))
probs = xgb.predict_proba(x_test)
preds = probs[:,1]
fprxgb, tprxgb, thresholdxgb = metrics.roc_curve(y_test, preds)
roc_aucxgb = metrics.auc(fprxgb, tprxgb)

ax.plot(fprxgb, tprxgb, 'b', label = 'AUC = %0.2f' % roc_aucxgb)
ax.plot([0, 1], [0, 1],'r--')
ax.set_title('Receiver Operating Characteristic XGBOOST ',fontsize=10)
ax.set_ylabel('True Positive Rate',fontsize=20)
ax.set_xlabel('False Positive Rate',fontsize=15)
ax.legend(loc = 'lower right', prop={'size': 16})

#Gradient
probs = gbk.predict_proba(x_test)
preds = probs[:,1]
fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, preds)
roc_aucgbk = metrics.auc(fprgbk, tprgbk)

ax1.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)
ax1.plot([0, 1], [0, 1],'r--')
ax1.set_title('Receiver Operating Characteristic GRADIENT BOOST ',fontsize=10)
ax1.set_ylabel('True Positive Rate',fontsize=20)
ax1.set_xlabel('False Positive Rate',fontsize=15)
ax1.legend(loc = 'lower right', prop={'size': 16})

plt.subplots_adjust(wspace=1)


# In[ ]:


fig, ax_arr = plt.subplots(nrows = 2, ncols = 2, figsize = (20,15))

#LOGMODEL
probs = logmodel.predict_proba(x_test)
preds = probs[:,1]
fprlog, tprlog, thresholdlog = metrics.roc_curve(y_test, preds)
roc_auclog = metrics.auc(fprlog, tprlog)

ax_arr[0,0].plot(fprlog, tprlog, 'b', label = 'AUC = %0.2f' % roc_auclog)
ax_arr[0,0].plot([0, 1], [0, 1],'r--')
ax_arr[0,0].set_title('Receiver Operating Characteristic Logistic ',fontsize=20)
ax_arr[0,0].set_ylabel('True Positive Rate',fontsize=20)
ax_arr[0,0].set_xlabel('False Positive Rate',fontsize=15)
ax_arr[0,0].legend(loc = 'lower right', prop={'size': 16})

#RANDOM FOREST --------------------
probs = rfc.predict_proba(x_test)
preds = probs[:,1]
fprrfc, tprrfc, thresholdrfc = metrics.roc_curve(y_test, preds)
roc_aucrfc = metrics.auc(fprrfc, tprrfc)

ax_arr[0,1].plot(fprrfc, tprrfc, 'b', label = 'AUC = %0.2f' % roc_aucrfc)
ax_arr[0,1].plot([0, 1], [0, 1],'r--')
ax_arr[0,1].set_title('Receiver Operating Characteristic Random Forest ',fontsize=20)
ax_arr[0,1].set_ylabel('True Positive Rate',fontsize=20)
ax_arr[0,1].set_xlabel('False Positive Rate',fontsize=15)
ax_arr[0,1].legend(loc = 'lower right', prop={'size': 16})

#KNN----------------------
probs = knn.predict_proba(x_test)
preds = probs[:,1]
fprknn, tprknn, thresholdknn = metrics.roc_curve(y_test, preds)
roc_aucknn = metrics.auc(fprknn, tprknn)

ax_arr[1,0].plot(fprknn, tprknn, 'b', label = 'AUC = %0.2f' % roc_aucknn)
ax_arr[1,0].plot([0, 1], [0, 1],'r--')
ax_arr[1,0].set_title('Receiver Operating Characteristic KNN ',fontsize=20)
ax_arr[1,0].set_ylabel('True Positive Rate',fontsize=20)
ax_arr[1,0].set_xlabel('False Positive Rate',fontsize=15)
ax_arr[1,0].legend(loc = 'lower right', prop={'size': 16})

#DECISION TREE ---------------------
probs = dt.predict_proba(x_test)
preds = probs[:,1]
fprdtree, tprdtree, thresholddtree = metrics.roc_curve(y_test, preds)
roc_aucdtree = metrics.auc(fprdtree, tprdtree)

ax_arr[1,1].plot(fprdtree, tprdtree, 'b', label = 'AUC = %0.2f' % roc_aucdtree)
ax_arr[1,1].plot([0, 1], [0, 1],'r--')
ax_arr[1,1].set_title('Receiver Operating Characteristic Decision Tree ',fontsize=20)
ax_arr[1,1].set_ylabel('True Positive Rate',fontsize=20)
ax_arr[1,1].set_xlabel('False Positive Rate',fontsize=15)
ax_arr[1,1].legend(loc = 'lower right', prop={'size': 16})


# In[ ]:




