{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a2e5f6dc-3011-e73c-bd39-23f6909f2b37"
   },
   "source": [
    "This is my first attempt on Kaggle so I decided to try using the sklearn framework that I am most comfortable with right now. So far, I am able to get the accuracy to about 86.73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "df66acdf-db88-4292-922e-ad5a1ce53a67"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "# Any results you write to the current directory are saved as output.\"\n",
    "\n",
    "# set pandas chained_assignment flag = None here\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "import matplotlib.patches as patches\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "#from packages import *\n",
    "#from ml_fairness import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "278f91bf-0b55-dd81-e65f-85df55ec6ec0"
   },
   "outputs": [],
   "source": [
    "def preprocess_target(dframe, df_column_name):\n",
    "    col = dframe[[df_column_name]]\n",
    "    le_col = LabelEncoder()\n",
    "    le_col.fit(np.ravel(col))\n",
    "    return le_col.transform(np.ravel(col))\n",
    "\n",
    "def preprocess_features(dframe):\n",
    "    for column in dframe:\n",
    "        enc = LabelEncoder()\n",
    "        if(column not in ['age','education.num','fnlwgt','capital.gain','capital.loss','hours.per.week']):\n",
    "            dframe[column] = enc.fit_transform(dframe[column])\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b6bd1726-9220-487e-9e1a-ef06ef6c55ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>education.num</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  education  marital.status  occupation  education.num  \\\n",
       "0       90          0         11               6           0              9   \n",
       "1       82          4         11               6           4              9   \n",
       "2       66          0         15               6           0             10   \n",
       "3       54          4          5               0           7              4   \n",
       "4       41          4         15               5          10             10   \n",
       "...    ...        ...        ...             ...         ...            ...   \n",
       "32556   22          4         15               4          11             10   \n",
       "32557   27          4          7               2          13             12   \n",
       "32558   40          4         11               2           7              9   \n",
       "32559   58          4         11               6           1              9   \n",
       "32560   22          4         11               4           1              9   \n",
       "\n",
       "       race  sex  relationship  capital.gain  capital.loss  native.country  \n",
       "0         4    0             1             0          4356              39  \n",
       "1         4    0             1             0          4356              39  \n",
       "2         2    0             4             0          4356              39  \n",
       "3         4    0             4             0          3900              39  \n",
       "4         4    0             3             0          3900              39  \n",
       "...     ...  ...           ...           ...           ...             ...  \n",
       "32556     4    1             1             0             0              39  \n",
       "32557     4    0             5             0             0              39  \n",
       "32558     4    1             0             0             0              39  \n",
       "32559     4    0             4             0             0              39  \n",
       "32560     4    1             3             0             0              39  \n",
       "\n",
       "[32561 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data and preprocess\n",
    "df = pd.read_csv('../../Data/adult.csv')\n",
    "\n",
    "# select and preprocess features\n",
    "le_data = LabelEncoder()\n",
    "features = ['age','workclass','education','marital.status','occupation','education.num','race','sex','relationship','capital.gain','capital.loss','native.country','income']\n",
    "data = df[features]\n",
    "data = preprocess_features(data)\n",
    "\n",
    "# select target\n",
    "data_new = data\n",
    "target = data['income']\n",
    "data = data.drop('income', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb1e318c-874c-9ffd-8161-f52da187f462"
   },
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bab2adca-9f0a-00db-e5fe-f8b4584d8ea3"
   },
   "outputs": [],
   "source": [
    "# select algorithm\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),algorithm=\"SAMME\",n_estimators=200)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(loss='deviance', n_estimators=100, learning_rate=1.0,max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6c87238-e66f-f13f-1d2c-61078074c8ae"
   },
   "outputs": [],
   "source": [
    "# fit and predict\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1120a4c6-e3cb-e52c-da9e-a43979acf665"
   },
   "outputs": [],
   "source": [
    "# display the relative importance of each attribute\n",
    "relval = clf.feature_importances_\n",
    "\n",
    "# horizontal bar plot of feature importance\n",
    "pos = np.arange(12) + 0.5\n",
    "plt.barh(pos, relval, align='center')\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.yticks(pos, ('Age','Working Class','Education','Marital Status','Occupation','Education Grade','Race','Sex','Relationship Status','Capital Gain','Capital Loss','Native Country'))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22c1bd91-5c08-6239-1f5b-8b78a812cd70"
   },
   "outputs": [],
   "source": [
    "# calc metrics\n",
    "true_negatives = 0\n",
    "false_negatives = 0\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "for prediction, truth in zip(predictions, y_test):\n",
    "    if prediction == 0 and truth == 0:\n",
    "        true_negatives += 1\n",
    "    elif prediction == 0 and truth == 1:\n",
    "        false_negatives += 1\n",
    "    elif prediction == 1 and truth == 0:\n",
    "        false_positives += 1\n",
    "    elif prediction == 1 and truth == 1:\n",
    "        true_positives += 1\n",
    "    else:\n",
    "        print (\"Warning: Found a predicted label not == 0 or 1.\")\n",
    "        print (\"All predictions should take value 0 or 1.\")\n",
    "        print (\"Evaluating performance for processed predictions:\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e2f94bee-13b2-8b8b-3d0f-98cd67bf04d3"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Test Dataset (40%):\")\n",
    "    print(\"true_positives\",true_positives)\n",
    "    print(\"true_negatives\",true_negatives)\n",
    "    print(\"false_positives\",false_positives)\n",
    "    print(\"false_negatives\",false_negatives)\n",
    "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "    print(\"total predictions:\",total_predictions)\n",
    "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "    print(\"accuracy:\",accuracy)\n",
    "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "    print(\"precision:\",precision)\n",
    "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "    print(\"recall\",recall)\n",
    "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "    print(\"f1\",f1)\n",
    "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "    print(\"f2\",f2)\n",
    "    print (clf)\n",
    "    #print (PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5))\n",
    "    #print (RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives))\n",
    "    print (\"\")\n",
    "except:\n",
    "    print (\"Got a divide by zero when trying out:\", clf)\n",
    "    print (\"Precision or recall may be undefined due to a lack of true positive predicitons.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DataFrame is created to stock differents models and fair metrics that we produce in this notebook\n",
    "algo_metrics = pd.DataFrame(columns=['model', 'fair_metrics', 'prediction', 'probs'])\n",
    "\n",
    "def add_to_df_algo_metrics(algo_metrics, model, fair_metrics, preds, probs, name):\n",
    "    return algo_metrics.append(pd.DataFrame(data=[[model, fair_metrics, preds, probs]], columns=['model', 'fair_metrics', 'prediction', 'probs'], index=[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metrics(dataset, pred, pred_is_dataset=False):\n",
    "    if pred_is_dataset:\n",
    "        dataset_pred = pred\n",
    "    else:\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = pred\n",
    "    \n",
    "    cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'average_abs_odds_difference',  'disparate_impact', 'theil_index']\n",
    "    obj_fairness = [[0,0,0,1,0]]\n",
    "    \n",
    "    fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "    \n",
    "    for attr in dataset_pred.protected_attribute_names:\n",
    "        idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "        privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "        unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "        \n",
    "        classified_metric = ClassificationMetric(dataset, \n",
    "                                                     dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        acc = classified_metric.accuracy()\n",
    "\n",
    "        row = pd.DataFrame([[metric_pred.mean_difference(),\n",
    "                                classified_metric.equal_opportunity_difference(),\n",
    "                                classified_metric.average_abs_odds_difference(),\n",
    "                                metric_pred.disparate_impact(),\n",
    "                                classified_metric.theil_index()]],\n",
    "                           columns  = cols,\n",
    "                           index = [attr]\n",
    "                          )\n",
    "        fair_metrics = fair_metrics.append(row)    \n",
    "    \n",
    "    fair_metrics = fair_metrics.replace([-np.inf, np.inf], 2)\n",
    "        \n",
    "    return fair_metrics\n",
    "\n",
    "def plot_fair_metrics(fair_metrics):\n",
    "    fig, ax = plt.subplots(figsize=(20,4), ncols=5, nrows=1)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left    =  0.125, \n",
    "        bottom  =  0.1, \n",
    "        right   =  0.9, \n",
    "        top     =  0.9, \n",
    "        wspace  =  .5, \n",
    "        hspace  =  1.1\n",
    "    )\n",
    "\n",
    "    y_title_margin = 1.2\n",
    "\n",
    "    plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    cols = fair_metrics.columns.values\n",
    "    obj = fair_metrics.loc['objective']\n",
    "    size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "    rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "    bottom = [-1,-1,-1,0,0]\n",
    "    top = [1,1,1,2,1]\n",
    "    bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "    display(Markdown(\"### Check bias metrics :\"))\n",
    "    display(Markdown(\"A model can be considered bias if just one of these five metrics show that this model is biased.\"))\n",
    "    for attr in fair_metrics.index[1:len(fair_metrics)].values:\n",
    "        display(Markdown(\"#### For the %s attribute :\"%attr))\n",
    "        check = [bound[i][0] < fair_metrics.loc[attr][i] < bound[i][1] for i in range(0,5)]\n",
    "        display(Markdown(\"With default thresholds, bias against unprivileged group detected in **%d** out of 5 metrics\"%(5 - sum(check))))\n",
    "\n",
    "    for i in range(0,5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "        \n",
    "        for j in range(0,len(fair_metrics)-1):\n",
    "            a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "            marg = -0.2 if val < 0 else 0.1\n",
    "            ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "        plt.ylim(bottom[i], top[i])\n",
    "        plt.setp(ax.patches, linewidth=0)\n",
    "        ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "        plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "        plt.title(cols[i])\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fair_metrics_and_plot(data, model, plot=False, model_aif=False):\n",
    "    pred = model.predict(data).labels if model_aif else model.predict(data.features)\n",
    "    # fair_metrics function available in the metrics.py file\n",
    "    fair = fair_metrics(data, pred)\n",
    "\n",
    "    if plot:\n",
    "        # plot_fair_metrics function available in the visualisations.py file\n",
    "        # The visualisation of this function is inspired by the dashboard on the demo of IBM aif360 \n",
    "        plot_fair_metrics(fair)\n",
    "        display(fair)\n",
    "    \n",
    "    return fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X)\n",
    "\n",
    "\n",
    "#combine_final = [train_df, test_df]\n",
    "#result = pd.concat(combine_final)\n",
    "#print(result.ifany())\n",
    "#print(result)\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "dataset_orig = StandardDataset(data_new,\n",
    "                                  label_name='income',\n",
    "                                  protected_attribute_names=['sex'],\n",
    "                                  favorable_classes=[1],\n",
    "                                  privileged_classes=[[1]])\n",
    "\n",
    "#metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "#                                             unprivileged_groups=unprivileged_groups,\n",
    "#                                             privileged_groups=privileged_groups)\n",
    "#display(Markdown(\"#### Original training dataset\"))\n",
    "#print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.196276\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "nb_fname = ipynbname.name()\n",
    "nb_path = ipynbname.path()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pickle\n",
    "\n",
    "data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "X_train = data_orig_train.features\n",
    "y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "X_test = data_orig_test.features\n",
    "y_test = data_orig_test.labels.ravel()\n",
    "num_estimators = 100\n",
    "\n",
    "model = GradientBoostingClassifier(loss='deviance', n_estimators=1, learning_rate=1.0,max_depth=2, random_state=0)\n",
    "\n",
    "mdl = model.fit(X_train, y_train)\n",
    "with open('../../Results/GBC/' + nb_fname + '.pkl', 'wb') as f:\n",
    "        pickle.dump(mdl, f)\n",
    "\n",
    "with open('../../Results/GBC/' + nb_fname + '_Train' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_train, f) \n",
    "    \n",
    "with open('../../Results/GBC/' + nb_fname + '_Test' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_test, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "final_metrics = []\n",
    "accuracy = []\n",
    "f1= []\n",
    "\n",
    "for i in range(1,num_estimators+1):\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators= i, learning_rate=1.0,max_depth=2, random_state=0, loss='deviance')\n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    fair_list.insert(0, i)\n",
    "    final_metrics.append(fair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>...</th>\n",
       "      <th>T90</th>\n",
       "      <th>T91</th>\n",
       "      <th>T92</th>\n",
       "      <th>T93</th>\n",
       "      <th>T94</th>\n",
       "      <th>T95</th>\n",
       "      <th>T96</th>\n",
       "      <th>T97</th>\n",
       "      <th>T98</th>\n",
       "      <th>T99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.869997</td>\n",
       "      <td>0.821067</td>\n",
       "      <td>0.839595</td>\n",
       "      <td>0.846453</td>\n",
       "      <td>0.843587</td>\n",
       "      <td>0.843075</td>\n",
       "      <td>0.844099</td>\n",
       "      <td>0.845225</td>\n",
       "      <td>0.847067</td>\n",
       "      <td>0.848910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868871</td>\n",
       "      <td>0.868871</td>\n",
       "      <td>0.868666</td>\n",
       "      <td>0.868871</td>\n",
       "      <td>0.868769</td>\n",
       "      <td>0.868769</td>\n",
       "      <td>0.868564</td>\n",
       "      <td>0.869178</td>\n",
       "      <td>0.869280</td>\n",
       "      <td>0.869997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.523186</td>\n",
       "      <td>0.604792</td>\n",
       "      <td>0.629080</td>\n",
       "      <td>0.611986</td>\n",
       "      <td>0.613367</td>\n",
       "      <td>0.611975</td>\n",
       "      <td>0.617796</td>\n",
       "      <td>0.625564</td>\n",
       "      <td>0.632470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705043</td>\n",
       "      <td>0.704907</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>0.704907</td>\n",
       "      <td>0.704744</td>\n",
       "      <td>0.704472</td>\n",
       "      <td>0.703875</td>\n",
       "      <td>0.705801</td>\n",
       "      <td>0.705557</td>\n",
       "      <td>0.706968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <td>-0.183827</td>\n",
       "      <td>-0.166884</td>\n",
       "      <td>-0.143830</td>\n",
       "      <td>-0.150066</td>\n",
       "      <td>-0.182743</td>\n",
       "      <td>-0.185535</td>\n",
       "      <td>-0.179820</td>\n",
       "      <td>-0.161690</td>\n",
       "      <td>-0.152730</td>\n",
       "      <td>-0.153993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187507</td>\n",
       "      <td>-0.187657</td>\n",
       "      <td>-0.187339</td>\n",
       "      <td>-0.187657</td>\n",
       "      <td>-0.187811</td>\n",
       "      <td>-0.183986</td>\n",
       "      <td>-0.185510</td>\n",
       "      <td>-0.184453</td>\n",
       "      <td>-0.184290</td>\n",
       "      <td>-0.183827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <td>-0.072391</td>\n",
       "      <td>-0.246539</td>\n",
       "      <td>-0.056392</td>\n",
       "      <td>-0.060173</td>\n",
       "      <td>-0.238734</td>\n",
       "      <td>-0.227913</td>\n",
       "      <td>-0.223696</td>\n",
       "      <td>-0.133076</td>\n",
       "      <td>-0.077557</td>\n",
       "      <td>-0.082003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084936</td>\n",
       "      <td>-0.087698</td>\n",
       "      <td>-0.091728</td>\n",
       "      <td>-0.087698</td>\n",
       "      <td>-0.087698</td>\n",
       "      <td>-0.076918</td>\n",
       "      <td>-0.085704</td>\n",
       "      <td>-0.072889</td>\n",
       "      <td>-0.071394</td>\n",
       "      <td>-0.072391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <td>0.070864</td>\n",
       "      <td>0.160599</td>\n",
       "      <td>0.056297</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>0.154799</td>\n",
       "      <td>0.151742</td>\n",
       "      <td>0.146839</td>\n",
       "      <td>0.097278</td>\n",
       "      <td>0.067588</td>\n",
       "      <td>0.069127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078537</td>\n",
       "      <td>0.079806</td>\n",
       "      <td>0.081486</td>\n",
       "      <td>0.079806</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.073174</td>\n",
       "      <td>0.077850</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.070924</td>\n",
       "      <td>0.070864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disparate_impact</th>\n",
       "      <td>-1.199121</td>\n",
       "      <td>-2.142558</td>\n",
       "      <td>-1.135429</td>\n",
       "      <td>-1.125965</td>\n",
       "      <td>-1.727185</td>\n",
       "      <td>-1.720900</td>\n",
       "      <td>-1.701447</td>\n",
       "      <td>-1.366819</td>\n",
       "      <td>-1.211665</td>\n",
       "      <td>-1.197980</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.226642</td>\n",
       "      <td>-1.229974</td>\n",
       "      <td>-1.234349</td>\n",
       "      <td>-1.229974</td>\n",
       "      <td>-1.230556</td>\n",
       "      <td>-1.197055</td>\n",
       "      <td>-1.213610</td>\n",
       "      <td>-1.196169</td>\n",
       "      <td>-1.200879</td>\n",
       "      <td>-1.199121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil_index</th>\n",
       "      <td>0.106252</td>\n",
       "      <td>0.170030</td>\n",
       "      <td>0.143530</td>\n",
       "      <td>0.135172</td>\n",
       "      <td>0.141621</td>\n",
       "      <td>0.140911</td>\n",
       "      <td>0.141760</td>\n",
       "      <td>0.139657</td>\n",
       "      <td>0.136899</td>\n",
       "      <td>0.134469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106709</td>\n",
       "      <td>0.106788</td>\n",
       "      <td>0.107254</td>\n",
       "      <td>0.106788</td>\n",
       "      <td>0.106822</td>\n",
       "      <td>0.106981</td>\n",
       "      <td>0.107209</td>\n",
       "      <td>0.106447</td>\n",
       "      <td>0.106651</td>\n",
       "      <td>0.106252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               classifier        T0        T1        T2  \\\n",
       "accuracy                         0.869997  0.821067  0.839595  0.846453   \n",
       "f1                               0.706968  0.523186  0.604792  0.629080   \n",
       "statistical_parity_difference   -0.183827 -0.166884 -0.143830 -0.150066   \n",
       "equal_opportunity_difference    -0.072391 -0.246539 -0.056392 -0.060173   \n",
       "average_abs_odds_difference      0.070864  0.160599  0.056297  0.058011   \n",
       "disparate_impact                -1.199121 -2.142558 -1.135429 -1.125965   \n",
       "theil_index                      0.106252  0.170030  0.143530  0.135172   \n",
       "\n",
       "                                     T3        T4        T5        T6  \\\n",
       "accuracy                       0.843587  0.843075  0.844099  0.845225   \n",
       "f1                             0.611986  0.613367  0.611975  0.617796   \n",
       "statistical_parity_difference -0.182743 -0.185535 -0.179820 -0.161690   \n",
       "equal_opportunity_difference  -0.238734 -0.227913 -0.223696 -0.133076   \n",
       "average_abs_odds_difference    0.154799  0.151742  0.146839  0.097278   \n",
       "disparate_impact              -1.727185 -1.720900 -1.701447 -1.366819   \n",
       "theil_index                    0.141621  0.140911  0.141760  0.139657   \n",
       "\n",
       "                                     T7        T8  ...       T90       T91  \\\n",
       "accuracy                       0.847067  0.848910  ...  0.868871  0.868871   \n",
       "f1                             0.625564  0.632470  ...  0.705043  0.704907   \n",
       "statistical_parity_difference -0.152730 -0.153993  ... -0.187507 -0.187657   \n",
       "equal_opportunity_difference  -0.077557 -0.082003  ... -0.084936 -0.087698   \n",
       "average_abs_odds_difference    0.067588  0.069127  ...  0.078537  0.079806   \n",
       "disparate_impact              -1.211665 -1.197980  ... -1.226642 -1.229974   \n",
       "theil_index                    0.136899  0.134469  ...  0.106709  0.106788   \n",
       "\n",
       "                                    T92       T93       T94       T95  \\\n",
       "accuracy                       0.868666  0.868871  0.868769  0.868769   \n",
       "f1                             0.703900  0.704907  0.704744  0.704472   \n",
       "statistical_parity_difference -0.187339 -0.187657 -0.187811 -0.183986   \n",
       "equal_opportunity_difference  -0.091728 -0.087698 -0.087698 -0.076918   \n",
       "average_abs_odds_difference    0.081486  0.079806  0.079918  0.073174   \n",
       "disparate_impact              -1.234349 -1.229974 -1.230556 -1.197055   \n",
       "theil_index                    0.107254  0.106788  0.106822  0.106981   \n",
       "\n",
       "                                    T96       T97       T98       T99  \n",
       "accuracy                       0.868564  0.869178  0.869280  0.869997  \n",
       "f1                             0.703875  0.705801  0.705557  0.706968  \n",
       "statistical_parity_difference -0.185510 -0.184453 -0.184290 -0.183827  \n",
       "equal_opportunity_difference  -0.085704 -0.072889 -0.071394 -0.072391  \n",
       "average_abs_odds_difference    0.077850  0.071554  0.070924  0.070864  \n",
       "disparate_impact              -1.213610 -1.196169 -1.200879 -1.199121  \n",
       "theil_index                    0.107209  0.106447  0.106651  0.106252  \n",
       "\n",
       "[7 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "final_result = pd.DataFrame(final_metrics)\n",
    "final_result[4] = np.log(final_result[4])\n",
    "final_result = final_result.transpose()\n",
    "final_result.loc[0] = f1  # add f1 and acc to df\n",
    "acc = pd.DataFrame(accuracy).transpose()\n",
    "acc = acc.rename(index={0: 'accuracy'})\n",
    "final_result = pd.concat([acc,final_result])\n",
    "final_result = final_result.rename(index={0: 'f1', 1: 'statistical_parity_difference', 2: 'equal_opportunity_difference', 3: 'average_abs_odds_difference', 4: 'disparate_impact', 5: 'theil_index'})\n",
    "final_result.columns = ['T' + str(col) for col in final_result.columns]\n",
    "final_result.insert(0, \"classifier\", final_result['T' + str(num_estimators - 1)])   ##Add final metrics add the beginning of the df\n",
    "final_result.to_csv('../../Results/GBC/' + nb_fname + '.csv')\n",
    "final_result"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
