{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging into Kaggle for the first time can be daunting. Our competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, we really think all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learning you could do on Kaggle, we've created a Getting Started tutorial for the Titanic competition. It walks you through the initial steps required to get your first decent submission on the leaderboard. By the end of the tutorial, you'll also have a solid understanding of how to use Kaggle's online coding environment, where you'll have trained your own machine learning model.\n",
    "\n",
    "So if this is your first time entering a Kaggle competition, regardless of whether you:\n",
    "- have experience with handling large datasets,\n",
    "- haven't done much coding,\n",
    "- are newer to data science, or\n",
    "- are relatively experienced (but are just unfamiliar with Kaggle's platform),\n",
    "\n",
    "you're in the right place! \n",
    "\n",
    "# Part 1: Get started\n",
    "\n",
    "In this section, you'll learn more about the competition and make your first submission. \n",
    "\n",
    "## Join the competition!\n",
    "\n",
    "The first thing to do is to join the competition!  Open a new window with **[the competition page](https://www.kaggle.com/c/titanic)**, and click on the **\"Join Competition\"** button, if you haven't already.  (_If you see a \"Submit Predictions\" button instead of a \"Join Competition\" button, you have already joined the competition, and don't need to do so again._)\n",
    "\n",
    "![](https://i.imgur.com/07cskyU.png)\n",
    "\n",
    "This takes you to the rules acceptance page.  You must accept the competition rules in order to participate.  These rules govern how many submissions you can make per day, the maximum team size, and other competition-specific details.   Then, click on **\"I Understand and Accept\"** to indicate that you will abide by the competition rules.\n",
    "\n",
    "## The challenge\n",
    "\n",
    "The competition is simple: we want you to use the Titanic passenger data (name, age, price of ticket, etc) to try to predict who will survive and who will die.\n",
    "\n",
    "## The data\n",
    "\n",
    "To take a look at the competition data, click on the **<a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\" rel=\"noopener noreferrer\"><b>Data tab</b></a>** at the top of the competition page.  Then, scroll down to find the list of files.  \n",
    "There are three files in the data: (1) **train.csv**, (2) **test.csv**, and (3) **gender_submission.csv**.\n",
    "\n",
    "### (1) train.csv\n",
    "\n",
    "**train.csv** contains the details of a subset of the passengers on board (891 passengers, to be exact -- where each passenger gets a different row in the table).  To investigate this data, click on the name of the file on the left of the screen.  Once you've done this, you can view all of the data in the window.  \n",
    "\n",
    "![](https://i.imgur.com/cYsdt0n.png)\n",
    "\n",
    "The values in the second column (**\"Survived\"**) can be used to determine whether each passenger survived or not: \n",
    "- if it's a \"1\", the passenger survived.\n",
    "- if it's a \"0\", the passenger died.\n",
    "\n",
    "For instance, the first passenger listed in **train.csv** is Mr. Owen Harris Braund.  He was 22 years old when he died on the Titanic.\n",
    "\n",
    "### (2) test.csv\n",
    "\n",
    "Using the patterns you find in **train.csv**, you have to predict whether the other 418 passengers on board (in **test.csv**) survived.  \n",
    "\n",
    "Click on **test.csv** (on the left of the screen) to examine its contents.  Note that **test.csv** does not have a **\"Survived\"** column - this information is hidden from you, and how well you do at predicting these hidden values will determine how highly you score in the competition! \n",
    "\n",
    "### (3) gender_submission.csv\n",
    "\n",
    "The **gender_submission.csv** file is provided as an example that shows how you should structure your predictions.  It predicts that all female passengers survived, and all male passengers died.  Your hypotheses regarding survival will probably be different, which will lead to a different submission file.  But, just like this file, your submission should have:\n",
    "- a **\"PassengerId\"** column containing the IDs of each passenger from **test.csv**.\n",
    "- a **\"Survived\"** column (that you will create!) with a \"1\" for the rows where you think the passenger survived, and a \"0\" where you predict that the passenger died."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Your coding environment\n",
    "\n",
    "In this section, you'll train your own machine learning model to improve your predictions.  _If you've never written code before or don't have any experience with machine learning, don't worry!  We don't assume any prior experience in this tutorial._\n",
    "\n",
    "## The Notebook\n",
    "\n",
    "The first thing to do is to create a Kaggle Notebook where you'll store all of your code.  You can use Kaggle Notebooks to getting up and running with writing code quickly, and without having to install anything on your computer.  (_If you are interested in deep learning, we also offer free GPU access!_) \n",
    "\n",
    "Begin by clicking on the **<a href=\"https://www.kaggle.com/c/titanic/kernels\" target=\"_blank\">Code tab</a>** on the competition page.  Then, click on **\"New Notebook\"**.\n",
    "\n",
    "![](https://i.imgur.com/v2i82Xd.png)\n",
    "\n",
    "Your notebook will take a few seconds to load.  In the top left corner, you can see the name of your notebook -- something like **\"kernel2daed3cd79\"**.\n",
    "\n",
    "![](https://i.imgur.com/64ZFT1L.png)\n",
    "\n",
    "You can edit the name by clicking on it.  Change it to something more descriptive, like **\"Getting Started with Titanic\"**.  \n",
    "\n",
    "![](https://i.imgur.com/uwyvzXq.png)\n",
    "\n",
    "## Your first lines of code\n",
    "\n",
    "When you start a new notebook, it has two gray boxes for storing code.  We refer to these gray boxes as \"code cells\".\n",
    "\n",
    "![](https://i.imgur.com/q9mwkZM.png)\n",
    "\n",
    "The first code cell already has some code in it.  To run this code, put your cursor in the code cell.  (_If your cursor is in the right place, you'll notice a blue vertical line to the left of the gray box._)  Then, either hit the play button (which appears to the left of the blue line), or hit **[Shift] + [Enter]** on your keyboard.\n",
    "\n",
    "If the code runs successfully, three lines of output are returned.  Below, you can see the same code that you just ran, along with the output that you should see in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "import matplotlib.patches as patches\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "#from packages import *\n",
    "#from ml_fairness import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us where the competition data is stored, so that we can load the files into the notebook.  We'll do that next.\n",
    "\n",
    "## Load the data\n",
    "\n",
    "The second code cell in your notebook now appears below the three lines of output with the file locations.\n",
    "\n",
    "![](https://i.imgur.com/OQBax9n.png)\n",
    "\n",
    "Type the two lines of code below into your second code cell.  Then, once you're done, either click on the blue play button, or hit **[Shift] + [Enter]**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../../Data/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should return the output above, which corresponds to the first five rows of the table in **train.csv**.  It's very important that you see this output **in your notebook** before proceeding with the tutorial!\n",
    "> _If your code does not produce this output_, double-check that your code is identical to the two lines above.  And, make sure your cursor is in the code cell before hitting **[Shift] + [Enter]**.\n",
    "\n",
    "The code that you've just written is in the Python programming language. It uses a Python \"module\" called **pandas** (abbreviated as `pd`) to load the table from the **train.csv** file into the notebook. To do this, we needed to plug in the location of the file (which we saw was `/kaggle/input/titanic/train.csv`).  \n",
    "> If you're not already familiar with Python (and pandas), the code shouldn't make sense to you -- but don't worry!  The point of this tutorial is to (quickly!) make your first submission to the competition.  At the end of the tutorial, we suggest resources to continue your learning.\n",
    "\n",
    "At this point, you should have at least three code cells in your notebook.  \n",
    "![](https://i.imgur.com/ReLhYca.png)\n",
    "\n",
    "Copy the code below into the third code cell of your notebook to load the contents of the **test.csv** file.  Don't forget to click on the play button (or hit **[Shift] + [Enter]**)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"../../Data/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, make sure that you see the output above in your notebook before continuing.  \n",
    "\n",
    "Once all of the code runs successfully, all of the data (in **train.csv** and **test.csv**) is loaded in the notebook.  (_The code above shows only the first 5 rows of each table, but all of the data is there -- all 891 rows of **train.csv** and all 418 rows of **test.csv**!_)\n",
    "\n",
    "# Part 3: Your first submission\n",
    "\n",
    "Remember our goal: we want to find patterns in **train.csv** that help us predict whether the passengers in **test.csv** survived.\n",
    "\n",
    "It might initially feel overwhelming to look for patterns, when there's so much data to sort through.  So, we'll start simple.\n",
    "\n",
    "## Explore a pattern\n",
    "\n",
    "Remember that the sample submission file in **gender_submission.csv** assumes that all female passengers survived (and all male passengers died).  \n",
    "\n",
    "Is this a reasonable first guess?  We'll check if this pattern holds true in the data (in **train.csv**).\n",
    "\n",
    "Copy the code below into a new code cell.  Then, run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of women who survived: 0.7420382165605095\n"
     ]
    }
   ],
   "source": [
    "women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n",
    "\n",
    "Then, run the code below in another code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of men who survived: 0.18890814558058924\n"
     ]
    }
   ],
   "source": [
    "men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n",
    "rate_men = sum(men)/len(men)\n",
    "\n",
    "print(\"% of men who survived:\", rate_men)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above calculates the percentage of male passengers (in **train.csv**) who survived.\n",
    "\n",
    "From this you can see that almost 75% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n",
    "\n",
    "But at the end of the day, this gender-based submission bases its predictions on only a single column.  As you can imagine, by considering multiple columns, we can discover more complex patterns that can potentially yield better-informed predictions.  Since it is quite difficult to consider several columns at once (or, it would take a long time to consider all possible patterns in many different columns simultaneously), we'll use machine learning to automate this for us.\n",
    "\n",
    "## Your first machine learning model\n",
    "\n",
    "We'll build what's known as a **random forest model**.  This model is constructed of several \"trees\" (there are three trees in the picture below, but we'll construct 100!) that will individually consider each passenger's data and vote on whether the individual survived.  Then, the random forest model makes a democratic decision: the outcome with the most votes wins!\n",
    "\n",
    "![](https://i.imgur.com/AC9Bq63.png)\n",
    "\n",
    "The code cell below looks for patterns in four different columns (**\"Pclass\"**, **\"Sex\"**, **\"SibSp\"**, and **\"Parch\"**) of the data.  It constructs the trees in the random forest model based on patterns in the **train.csv** file, before generating predictions for the passengers in **test.csv**.  The code also saves these new predictions in a CSV file **submission.csv**.\n",
    "\n",
    "Copy this code into your notebook, and run it in a new code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DataFrame is created to stock differents models and fair metrics that we produce in this notebook\n",
    "algo_metrics = pd.DataFrame(columns=['model', 'fair_metrics', 'prediction', 'probs'])\n",
    "\n",
    "def add_to_df_algo_metrics(algo_metrics, model, fair_metrics, preds, probs, name):\n",
    "    return algo_metrics.append(pd.DataFrame(data=[[model, fair_metrics, preds, probs]], columns=['model', 'fair_metrics', 'prediction', 'probs'], index=[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metrics(dataset, pred, pred_is_dataset=False):\n",
    "    if pred_is_dataset:\n",
    "        dataset_pred = pred\n",
    "    else:\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = pred\n",
    "    \n",
    "    cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'average_abs_odds_difference',  'disparate_impact', 'theil_index']\n",
    "    obj_fairness = [[0,0,0,1,0]]\n",
    "    \n",
    "    fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "    \n",
    "    for attr in dataset_pred.protected_attribute_names:\n",
    "        idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "        privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "        unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "        \n",
    "        classified_metric = ClassificationMetric(dataset, \n",
    "                                                     dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        acc = classified_metric.accuracy()\n",
    "\n",
    "        row = pd.DataFrame([[metric_pred.mean_difference(),\n",
    "                                classified_metric.equal_opportunity_difference(),\n",
    "                                classified_metric.average_abs_odds_difference(),\n",
    "                                metric_pred.disparate_impact(),\n",
    "                                classified_metric.theil_index()]],\n",
    "                           columns  = cols,\n",
    "                           index = [attr]\n",
    "                          )\n",
    "        fair_metrics = fair_metrics.append(row)    \n",
    "    \n",
    "    fair_metrics = fair_metrics.replace([-np.inf, np.inf], 2)\n",
    "        \n",
    "    return fair_metrics\n",
    "\n",
    "def plot_fair_metrics(fair_metrics):\n",
    "    fig, ax = plt.subplots(figsize=(20,4), ncols=5, nrows=1)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left    =  0.125, \n",
    "        bottom  =  0.1, \n",
    "        right   =  0.9, \n",
    "        top     =  0.9, \n",
    "        wspace  =  .5, \n",
    "        hspace  =  1.1\n",
    "    )\n",
    "\n",
    "    y_title_margin = 1.2\n",
    "\n",
    "    plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    cols = fair_metrics.columns.values\n",
    "    obj = fair_metrics.loc['objective']\n",
    "    size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "    rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "    bottom = [-1,-1,-1,0,0]\n",
    "    top = [1,1,1,2,1]\n",
    "    bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "    display(Markdown(\"### Check bias metrics :\"))\n",
    "    display(Markdown(\"A model can be considered bias if just one of these five metrics show that this model is biased.\"))\n",
    "    for attr in fair_metrics.index[1:len(fair_metrics)].values:\n",
    "        display(Markdown(\"#### For the %s attribute :\"%attr))\n",
    "        check = [bound[i][0] < fair_metrics.loc[attr][i] < bound[i][1] for i in range(0,5)]\n",
    "        display(Markdown(\"With default thresholds, bias against unprivileged group detected in **%d** out of 5 metrics\"%(5 - sum(check))))\n",
    "\n",
    "    for i in range(0,5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "        \n",
    "        for j in range(0,len(fair_metrics)-1):\n",
    "            a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "            marg = -0.2 if val < 0 else 0.1\n",
    "            ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "        plt.ylim(bottom[i], top[i])\n",
    "        plt.setp(ax.patches, linewidth=0)\n",
    "        ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "        plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "        plt.title(cols[i])\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fair_metrics_and_plot(data, model, plot=False, model_aif=False):\n",
    "    pred = model.predict(data).labels if model_aif else model.predict(data.features)\n",
    "    # fair_metrics function available in the metrics.py file\n",
    "    fair = fair_metrics(data, pred)\n",
    "\n",
    "    if plot:\n",
    "        # plot_fair_metrics function available in the visualisations.py file\n",
    "        # The visualisation of this function is inspired by the dashboard on the demo of IBM aif360 \n",
    "        plot_fair_metrics(fair)\n",
    "        display(fair)\n",
    "    \n",
    "    return fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Sex'] = train_data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "train_data.head()\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Survived\"]\n",
    "X = pd.get_dummies(train_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex  SibSp  Parch  Survived\n",
      "0         3    0      1      0         0\n",
      "1         1    1      1      0         1\n",
      "2         3    1      0      0         1\n",
      "3         1    1      1      0         1\n",
      "4         3    0      0      0         0\n",
      "..      ...  ...    ...    ...       ...\n",
      "886       2    0      0      0         0\n",
      "887       1    1      0      0         1\n",
      "888       3    1      1      2         0\n",
      "889       1    0      0      0         1\n",
      "890       3    0      0      0         0\n",
      "\n",
      "[891 rows x 5 columns]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "check_nan = X['Survived'].isnull().values.any()\n",
    "print(check_nan)\n",
    "\n",
    "#combine_final = [train_df, test_df]\n",
    "#result = pd.concat(combine_final)\n",
    "#print(result.ifany())\n",
    "#print(result)\n",
    "privileged_groups = [{'Sex': 1}]\n",
    "unprivileged_groups = [{'Sex': 0}]\n",
    "dataset_orig = StandardDataset(X,\n",
    "                                  label_name='Survived',\n",
    "                                  protected_attribute_names=['Sex'],\n",
    "                                  favorable_classes=[1],\n",
    "                                  privileged_classes=[[1]])\n",
    "\n",
    "#metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "#                                             unprivileged_groups=unprivileged_groups,\n",
    "#                                             privileged_groups=privileged_groups)\n",
    "#display(Markdown(\"#### Original training dataset\"))\n",
    "#print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.553130\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "nb_fname = ipynbname.name()\n",
    "nb_path = ipynbname.path()\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "X_train = data_orig_train.features\n",
    "y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "X_test = data_orig_test.features\n",
    "y_test = data_orig_test.labels.ravel()\n",
    "num_estimators = 100\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "\n",
    "\n",
    "mdl = model.fit(X_train, y_train)\n",
    "with open('../../Results/RF/' + nb_fname + '.pkl', 'wb') as f:\n",
    "        pickle.dump(mdl, f)\n",
    "\n",
    "with open('../../Results/RF/' + nb_fname + '_Train' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_train, f) \n",
    "    \n",
    "with open('../../Results/RF/' + nb_fname + '_Test' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_test, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "STD [5.91607978 0.04119786 0.0540599  0.05153083 0.01749403 0.02516635]\n",
      "[9.5, -0.7760868602496473, -0.8183481793209029, 0.6960387151534388, -2.842161348219195, 0.1821959070586201]\n",
      "-3.5583617655776862\n",
      "0.778544776119403\n",
      "0.6877677129425662\n"
     ]
    }
   ],
   "source": [
    "final_metrics = []\n",
    "accuracy = []\n",
    "f1= []\n",
    "from statistics import mean\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "for i in range(0,20):\n",
    "    \n",
    "    data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "    print(i)\n",
    "    X_train = data_orig_train.features\n",
    "    y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "    X_test = data_orig_test.features\n",
    "    y_test = data_orig_test.labels.ravel()\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "  \n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    fair_list.insert(0, i)\n",
    "    final_metrics.append(fair_list)\n",
    "\n",
    "    \n",
    "element_wise_std =  np.std(final_metrics, 0, ddof=1)\n",
    "print(\"STD \" + str(element_wise_std))\n",
    "final_metrics = list(map(mean, zip(*final_metrics)))\n",
    "accuracy = mean(accuracy)\n",
    "f1 = mean(f1)\n",
    "final_metrics[4] = np.log(final_metrics[4])\n",
    "print(final_metrics)\n",
    "print(sum(final_metrics[1:]))\n",
    "print(accuracy)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "final_metrics = []\n",
    "accuracy = []\n",
    "f1= []\n",
    "\n",
    "for i in range(1,num_estimators+1):\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=i, max_depth=5, random_state=1)\n",
    "\n",
    "    \n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    fair_list.insert(0, i)\n",
    "    final_metrics.append(fair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1         2         3         4         5\n",
      "0     1 -0.866640 -0.750000  0.751250  0.100449  0.134797\n",
      "1     2 -0.829662 -0.843434  0.686301  0.055108  0.160174\n",
      "2     3 -0.829662 -0.843434  0.686301  0.055108  0.160174\n",
      "3     4 -0.867296 -0.926768  0.741301  0.012246  0.168110\n",
      "4     5 -0.824285 -0.843434  0.682967  0.061231  0.161407\n",
      "..  ...       ...       ...       ...       ...       ...\n",
      "95   96 -0.936533 -0.944444  0.868472  0.027903  0.158249\n",
      "96   97 -0.936533 -0.944444  0.868472  0.027903  0.158249\n",
      "97   98 -0.936533 -0.944444  0.868472  0.027903  0.158249\n",
      "98   99 -0.936533 -0.944444  0.868472  0.027903  0.158249\n",
      "99  100 -0.936533 -0.944444  0.868472  0.027903  0.158249\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>...</th>\n",
       "      <th>T90</th>\n",
       "      <th>T91</th>\n",
       "      <th>T92</th>\n",
       "      <th>T93</th>\n",
       "      <th>T94</th>\n",
       "      <th>T95</th>\n",
       "      <th>T96</th>\n",
       "      <th>T97</th>\n",
       "      <th>T98</th>\n",
       "      <th>T99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.817164</td>\n",
       "      <td>0.817164</td>\n",
       "      <td>0.817164</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.817164</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.817164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.731183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.866640</td>\n",
       "      <td>-0.829662</td>\n",
       "      <td>-0.829662</td>\n",
       "      <td>-0.867296</td>\n",
       "      <td>-0.824285</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.952662</td>\n",
       "      <td>-0.915028</td>\n",
       "      <td>-0.903881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "      <td>-0.936533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.843434</td>\n",
       "      <td>-0.843434</td>\n",
       "      <td>-0.926768</td>\n",
       "      <td>-0.843434</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.972222</td>\n",
       "      <td>-0.888889</td>\n",
       "      <td>-0.941919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "      <td>-0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>0.686301</td>\n",
       "      <td>0.686301</td>\n",
       "      <td>0.741301</td>\n",
       "      <td>0.682967</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.889028</td>\n",
       "      <td>0.834028</td>\n",
       "      <td>0.811376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "      <td>0.868472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disparate_impact</th>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-2.298104</td>\n",
       "      <td>-2.898469</td>\n",
       "      <td>-2.898469</td>\n",
       "      <td>-4.402546</td>\n",
       "      <td>-2.793108</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-4.495328</td>\n",
       "      <td>-2.991251</td>\n",
       "      <td>-4.443368</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "      <td>-3.579037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil_index</th>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.134797</td>\n",
       "      <td>0.160174</td>\n",
       "      <td>0.160174</td>\n",
       "      <td>0.168110</td>\n",
       "      <td>0.161407</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.160174</td>\n",
       "      <td>0.151894</td>\n",
       "      <td>0.166385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>0.158249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               classifier        T0        T1        T2  \\\n",
       "accuracy                         0.813433  0.817164  0.817164  0.817164   \n",
       "f1                               0.731183  0.753769  0.732240  0.732240   \n",
       "statistical_parity_difference   -0.936533 -0.866640 -0.829662 -0.829662   \n",
       "equal_opportunity_difference    -0.944444 -0.750000 -0.843434 -0.843434   \n",
       "average_abs_odds_difference      0.868472  0.751250  0.686301  0.686301   \n",
       "disparate_impact                -3.579037 -2.298104 -2.898469 -2.898469   \n",
       "theil_index                      0.158249  0.134797  0.160174  0.160174   \n",
       "\n",
       "                                     T3        T4        T5        T6  \\\n",
       "accuracy                       0.820896  0.813433  0.813433  0.817164   \n",
       "f1                             0.727273  0.728261  0.731183  0.732240   \n",
       "statistical_parity_difference -0.867296 -0.824285 -0.936533 -0.952662   \n",
       "equal_opportunity_difference  -0.926768 -0.843434 -0.944444 -0.972222   \n",
       "average_abs_odds_difference    0.741301  0.682967  0.868472  0.889028   \n",
       "disparate_impact              -4.402546 -2.793108 -3.579037 -4.495328   \n",
       "theil_index                    0.168110  0.161407  0.158249  0.160174   \n",
       "\n",
       "                                     T7        T8  ...       T90       T91  \\\n",
       "accuracy                       0.813433  0.817164  ...  0.813433  0.813433   \n",
       "f1                             0.736842  0.726257  ...  0.731183  0.731183   \n",
       "statistical_parity_difference -0.915028 -0.903881  ... -0.936533 -0.936533   \n",
       "equal_opportunity_difference  -0.888889 -0.941919  ... -0.944444 -0.944444   \n",
       "average_abs_odds_difference    0.834028  0.811376  ...  0.868472  0.868472   \n",
       "disparate_impact              -2.991251 -4.443368  ... -3.579037 -3.579037   \n",
       "theil_index                    0.151894  0.166385  ...  0.158249  0.158249   \n",
       "\n",
       "                                    T92       T93       T94       T95  \\\n",
       "accuracy                       0.813433  0.813433  0.813433  0.813433   \n",
       "f1                             0.731183  0.731183  0.731183  0.731183   \n",
       "statistical_parity_difference -0.936533 -0.936533 -0.936533 -0.936533   \n",
       "equal_opportunity_difference  -0.944444 -0.944444 -0.944444 -0.944444   \n",
       "average_abs_odds_difference    0.868472  0.868472  0.868472  0.868472   \n",
       "disparate_impact              -3.579037 -3.579037 -3.579037 -3.579037   \n",
       "theil_index                    0.158249  0.158249  0.158249  0.158249   \n",
       "\n",
       "                                    T96       T97       T98       T99  \n",
       "accuracy                       0.813433  0.813433  0.813433  0.813433  \n",
       "f1                             0.731183  0.731183  0.731183  0.731183  \n",
       "statistical_parity_difference -0.936533 -0.936533 -0.936533 -0.936533  \n",
       "equal_opportunity_difference  -0.944444 -0.944444 -0.944444 -0.944444  \n",
       "average_abs_odds_difference    0.868472  0.868472  0.868472  0.868472  \n",
       "disparate_impact              -3.579037 -3.579037 -3.579037 -3.579037  \n",
       "theil_index                    0.158249  0.158249  0.158249  0.158249  \n",
       "\n",
       "[7 rows x 101 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "final_result = pd.DataFrame(final_metrics)\n",
    "print(final_result)\n",
    "final_result[4] = np.log(final_result[4])\n",
    "final_result = final_result.transpose()\n",
    "final_result.loc[0] = f1  # add f1 and acc to df\n",
    "acc = pd.DataFrame(accuracy).transpose()\n",
    "acc = acc.rename(index={0: 'accuracy'})\n",
    "final_result = pd.concat([acc,final_result])\n",
    "final_result = final_result.rename(index={0: 'f1', 1: 'statistical_parity_difference', 2: 'equal_opportunity_difference', 3: 'average_abs_odds_difference', 4: 'disparate_impact', 5: 'theil_index'})\n",
    "final_result.columns = ['T' + str(col) for col in final_result.columns]\n",
    "final_result.insert(0, \"classifier\", final_result['T' + str(num_estimators - 1)])   ##Add final metrics add the beginning of the df\n",
    "final_result.to_csv('../../Results/RF/' + nb_fname + '.csv')\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your notebook outputs the same message above (`Your submission was successfully saved!`) before moving on.\n",
    "> Again, don't worry if this code doesn't make sense to you!  For now, we'll focus on how to generate and submit predictions.\n",
    "\n",
    "Once you're ready, click on the **\"Save Version\"** button in the top right corner of your notebook.  This will generate a pop-up window.  \n",
    "- Ensure that the **\"Save and Run All\"** option is selected, and then click on the **\"Save\"** button.\n",
    "- This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **\"Save Version\"** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  \n",
    "- Click on the **Output** tab on the right of the screen.  Then, click on the **\"Submit\"** button to submit your results.\n",
    "\n",
    "![](https://i.imgur.com/1ocaUl4.png)\n",
    "\n",
    "Congratulations for making your first submission to a Kaggle competition!  Within ten minutes, you should receive a message providing your spot on the leaderboard.  Great work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Learn more!\n",
    "\n",
    "If you're interested in learning more, we strongly suggest our (3-hour) **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course, which will help you fully understand all of the code that we've presented here.  You'll also know enough to generate even better predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = model.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_features='auto', random_state=1833147958)\n"
     ]
    }
   ],
   "source": [
    "print(trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = trees[0].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
