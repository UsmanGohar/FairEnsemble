{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "25b1e1db-8bc5-7029-f719-91da523bd121"
   },
   "source": [
    "## Introduction ##\n",
    "\n",
    "This is my first work of machine learning. the notebook is written in python and has inspired from [\"Exploring Survival on Titanic\" by Megan Risdal, a Kernel in R on Kaggle][1].\n",
    "\n",
    "\n",
    "  [1]: https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2ce68358-02ec-556d-ba88-e773a50bc18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "\n",
    "train = pd.read_csv('../../Data/train.csv', header = 0, dtype={'Age': np.float64})\n",
    "test  = pd.read_csv('../../Data/test.csv' , header = 0, dtype={'Age': np.float64})\n",
    "full_data = [train, test]\n",
    "\n",
    "print (train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "import matplotlib.patches as patches\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "#from packages import *\n",
    "#from ml_fairness import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9595646-65c9-6fc4-395f-0befc4d122ce"
   },
   "source": [
    "# Feature Engineering #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9b4c278b-aaca-e92c-ba77-b9b48379d1f1"
   },
   "source": [
    "## 1. Pclass ##\n",
    "there is no missing value on this feature and already a numerical value. so let's check it's impact on our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "4680d950-cf7d-a6ae-e813-535e2247d88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e70f81c-d4e2-1823-f0ba-a7c9b46984ff"
   },
   "source": [
    "## 2. Sex ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "6729681d-7915-1631-78d2-ddf3c35a424c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n"
     ]
    }
   ],
   "source": [
    "print (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c58b7ee-d6a1-0cc9-2346-81c47846a54a"
   },
   "source": [
    "## 3. SibSp and Parch ##\n",
    "With the number of siblings/spouse and the number of children/parents we can create new feature called Family Size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1a537f10-7cec-d0b7-8a34-fa9975655190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "print (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4861d3e-10db-1a23-8728-44e4d5251844"
   },
   "source": [
    "it seems has a good effect on our prediction but let's go further and categorize people to check whether they are alone in this ship or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8c35e945-c928-e3bc-bd9c-d6ddb287e4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IsAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "print (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2780ca4e-7923-b845-0b6b-5f68a45f6b93"
   },
   "source": [
    "good! the impact is considerable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8aa419c0-6614-7efc-7797-97f4a5158b19"
   },
   "source": [
    "## 4. Embarked ##\n",
    "the embarked feature has some missing value. and we try to fill those with the most occurred value ( 'S' )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "0e70e9af-d7cc-8c40-b7d4-2643889c376d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "print (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e08c9ee8-d6d1-99b7-38bd-f0042c18a5d9"
   },
   "source": [
    "## 5. Fare ##\n",
    "Fare also has some missing value and we will replace it with the median. then we categorize it into 4 ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "a21335bd-4e8d-66e8-e6a5-5d2173b72d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CategoricalFare  Survived\n",
      "0   (-0.001, 7.91]  0.197309\n",
      "1   (7.91, 14.454]  0.303571\n",
      "2   (14.454, 31.0]  0.454955\n",
      "3  (31.0, 512.329]  0.581081\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "print (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ec8d1b22-a95f-9f16-77ab-7b60d2103852"
   },
   "source": [
    "## 6. Age ##\n",
    "we have plenty of missing values in this feature. # generate random numbers between (mean - std) and (mean + std).\n",
    "then we categorize age into 5 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b90c2870-ce5d-ae0e-a33d-59e35445500e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CategoricalAge  Survived\n",
      "0  (-0.08, 16.0]  0.530973\n",
      "1   (16.0, 32.0]  0.353741\n",
      "2   (32.0, 48.0]  0.369650\n",
      "3   (48.0, 64.0]  0.434783\n",
      "4   (64.0, 80.0]  0.090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    age_avg \t   = dataset['Age'].mean()\n",
    "    age_std \t   = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "print (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd25ec3f-b601-c1cc-d701-991fac1621f9"
   },
   "source": [
    "## 7. Name ##\n",
    "inside this feature we can find the title of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "ad042f43-bfe0-ded0-4171-379d8caaa749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex       female  male\n",
      "Title                 \n",
      "Capt           0     1\n",
      "Col            0     2\n",
      "Countess       1     0\n",
      "Don            0     1\n",
      "Dr             1     6\n",
      "Jonkheer       0     1\n",
      "Lady           1     0\n",
      "Major          0     2\n",
      "Master         0    40\n",
      "Miss         182     0\n",
      "Mlle           2     0\n",
      "Mme            1     0\n",
      "Mr             0   517\n",
      "Mrs          125     0\n",
      "Ms             1     0\n",
      "Rev            0     6\n",
      "Sir            0     1\n"
     ]
    }
   ],
   "source": [
    "def get_title(name):\n",
    "\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "\t# If the title exists, extract and return it.\n",
    "\tif title_search:\n",
    "\t\treturn title_search.group(1)\n",
    "\treturn \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "print(pd.crosstab(train['Title'], train['Sex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca5fff8c-7a0d-6c18-2173-b8df6293c50a"
   },
   "source": [
    " so we have titles. let's categorize it and check the title impact on survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "8357238b-98fe-632a-acd5-33674a6132ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Miss  0.702703\n",
      "2      Mr  0.156673\n",
      "3     Mrs  0.793651\n",
      "4    Rare  0.347826\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68fa2057-e27a-e252-0d1b-869c00a303ba"
   },
   "source": [
    "# Data Cleaning #\n",
    "great! now let's clean our data and map our features into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "2502bb70-ce6f-2497-7331-7d1f80521470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Age  Fare  Embarked  IsAlone  Title\n",
      "0         0       3    0    1     0         0        0      1\n",
      "1         1       1    1    2     3         1        0      3\n",
      "2         1       3    1    1     1         0        1      2\n",
      "3         1       1    1    2     3         0        0      3\n",
      "4         0       3    0    2     1         0        1      1\n",
      "5         0       3    0    2     1         2        1      1\n",
      "6         0       1    0    3     3         0        1      1\n",
      "7         0       3    0    0     2         0        0      4\n",
      "8         1       3    1    1     1         0        0      3\n",
      "9         1       2    1    0     2         1        0      3\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "\n",
    "# Feature Selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n",
    "                 'Parch', 'FamilySize']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "print (train.head(10))\n",
    "train_df = train\n",
    "train = train.values\n",
    "test  = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8aaaf2bc-e282-79cc-008a-e2e801b51b07"
   },
   "source": [
    "good! now we have a clean dataset and ready to predict. let's find which classifier works better on this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "23b55b45-572b-7276-32e7-8f7a0dcfd25e"
   },
   "source": [
    "# Classifier Comparison #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "31ded30a-8de4-6507-e7f7-5805a0f1eaf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Classifier Accuracy'}, xlabel='Accuracy', ylabel='Classifier'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "\tAdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log \t = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "X = train[0::, 1::]\n",
    "y = train[0::, 0]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "\tX_train, X_test = X[train_index], X[test_index]\n",
    "\ty_train, y_test = y[train_index], y[test_index]\n",
    "\t\n",
    "\tfor clf in classifiers:\n",
    "\t\tname = clf.__class__.__name__\n",
    "\t\tclf.fit(X_train, y_train)\n",
    "\t\ttrain_predictions = clf.predict(X_test)\n",
    "\t\tacc = accuracy_score(y_test, train_predictions)\n",
    "\t\tif name in acc_dict:\n",
    "\t\t\tacc_dict[name] += acc\n",
    "\t\telse:\n",
    "\t\t\tacc_dict[name] = acc\n",
    "\n",
    "for clf in acc_dict:\n",
    "\tacc_dict[clf] = acc_dict[clf] / 10.0\n",
    "\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
    "\tlog = log.append(log_entry)\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "438585cf-b7ad-73ba-49aa-87688ff21233"
   },
   "source": [
    "# Prediction #\n",
    "now we can use SVC classifier to predict our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "24967b57-732b-7180-bfd5-005beff75974"
   },
   "outputs": [],
   "source": [
    "candidate_classifier = SVC()\n",
    "candidate_classifier.fit(train[0::, 1::], train[0::, 0])\n",
    "result = candidate_classifier.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DataFrame is created to stock differents models and fair metrics that we produce in this notebook\n",
    "algo_metrics = pd.DataFrame(columns=['model', 'fair_metrics', 'prediction', 'probs'])\n",
    "\n",
    "def add_to_df_algo_metrics(algo_metrics, model, fair_metrics, preds, probs, name):\n",
    "    return algo_metrics.append(pd.DataFrame(data=[[model, fair_metrics, preds, probs]], columns=['model', 'fair_metrics', 'prediction', 'probs'], index=[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metrics(dataset, pred, pred_is_dataset=False):\n",
    "    if pred_is_dataset:\n",
    "        dataset_pred = pred\n",
    "    else:\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = pred\n",
    "    \n",
    "    cols = ['statistical_parity_difference', 'equal_opportunity_difference', 'average_abs_odds_difference',  'disparate_impact', 'theil_index']\n",
    "    obj_fairness = [[0,0,0,1,0]]\n",
    "    \n",
    "    fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "    \n",
    "    for attr in dataset_pred.protected_attribute_names:\n",
    "        idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "        privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "        unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "        \n",
    "        classified_metric = ClassificationMetric(dataset, \n",
    "                                                     dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_pred = BinaryLabelDatasetMetric(dataset_pred,\n",
    "                                                     unprivileged_groups=unprivileged_groups,\n",
    "                                                     privileged_groups=privileged_groups)\n",
    "\n",
    "        acc = classified_metric.accuracy()\n",
    "\n",
    "        row = pd.DataFrame([[metric_pred.mean_difference(),\n",
    "                                classified_metric.equal_opportunity_difference(),\n",
    "                                classified_metric.average_abs_odds_difference(),\n",
    "                                metric_pred.disparate_impact(),\n",
    "                                classified_metric.theil_index()]],\n",
    "                           columns  = cols,\n",
    "                           index = [attr]\n",
    "                          )\n",
    "        fair_metrics = fair_metrics.append(row)    \n",
    "    \n",
    "    fair_metrics = fair_metrics.replace([-np.inf, np.inf], 2)\n",
    "        \n",
    "    return fair_metrics\n",
    "\n",
    "def plot_fair_metrics(fair_metrics):\n",
    "    fig, ax = plt.subplots(figsize=(20,4), ncols=5, nrows=1)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left    =  0.125, \n",
    "        bottom  =  0.1, \n",
    "        right   =  0.9, \n",
    "        top     =  0.9, \n",
    "        wspace  =  .5, \n",
    "        hspace  =  1.1\n",
    "    )\n",
    "\n",
    "    y_title_margin = 1.2\n",
    "\n",
    "    plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    cols = fair_metrics.columns.values\n",
    "    obj = fair_metrics.loc['objective']\n",
    "    size_rect = [0.2,0.2,0.2,0.4,0.25]\n",
    "    rect = [-0.1,-0.1,-0.1,0.8,0]\n",
    "    bottom = [-1,-1,-1,0,0]\n",
    "    top = [1,1,1,2,1]\n",
    "    bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2],[0,0.25]]\n",
    "\n",
    "    display(Markdown(\"### Check bias metrics :\"))\n",
    "    display(Markdown(\"A model can be considered bias if just one of these five metrics show that this model is biased.\"))\n",
    "    for attr in fair_metrics.index[1:len(fair_metrics)].values:\n",
    "        display(Markdown(\"#### For the %s attribute :\"%attr))\n",
    "        check = [bound[i][0] < fair_metrics.loc[attr][i] < bound[i][1] for i in range(0,5)]\n",
    "        display(Markdown(\"With default thresholds, bias against unprivileged group detected in **%d** out of 5 metrics\"%(5 - sum(check))))\n",
    "\n",
    "    for i in range(0,5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "        \n",
    "        for j in range(0,len(fair_metrics)-1):\n",
    "            a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "            marg = -0.2 if val < 0 else 0.1\n",
    "            ax.text(a.get_x()+a.get_width()/5, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "        plt.ylim(bottom[i], top[i])\n",
    "        plt.setp(ax.patches, linewidth=0)\n",
    "        ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "        plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "        plt.title(cols[i])\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fair_metrics_and_plot(data, model, plot=False, model_aif=False):\n",
    "    pred = model.predict(data).labels if model_aif else model.predict(data.features)\n",
    "    # fair_metrics function available in the metrics.py file\n",
    "    fair = fair_metrics(data, pred)\n",
    "\n",
    "    if plot:\n",
    "        # plot_fair_metrics function available in the visualisations.py file\n",
    "        # The visualisation of this function is inspired by the dashboard on the demo of IBM aif360 \n",
    "        plot_fair_metrics(fair)\n",
    "        display(fair)\n",
    "    \n",
    "    return fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  Fare  Embarked  IsAlone  Title\n",
       "0           0       3    0    1     0         0        0      1\n",
       "1           1       1    1    2     3         1        0      3\n",
       "2           1       3    1    1     1         0        1      2\n",
       "3           1       1    1    2     3         0        0      3\n",
       "4           0       3    0    2     1         0        1      1\n",
       "..        ...     ...  ...  ...   ...       ...      ...    ...\n",
       "886         0       2    0    1     1         0        1      5\n",
       "887         1       1    1    1     2         0        1      2\n",
       "888         0       3    1    0     2         0        0      2\n",
       "889         1       1    0    1     2         1        1      1\n",
       "890         0       3    0    1     0         2        1      1\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##train['Sex'] = train['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "train_df\n",
    "\n",
    "#features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Survived\"]\n",
    "#X = pd.get_dummies(train_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Sex': 1}]\n",
    "unprivileged_groups = [{'Sex': 0}]\n",
    "dataset_orig = StandardDataset(train_df,\n",
    "                                  label_name='Survived',\n",
    "                                  protected_attribute_names=['Sex'],\n",
    "                                  favorable_classes=[1],\n",
    "                                  privileged_classes=[[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.553130\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "nb_fname = ipynbname.name()\n",
    "nb_path = ipynbname.path()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pickle\n",
    "\n",
    "data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "X_train = data_orig_train.features\n",
    "y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "X_test = data_orig_test.features\n",
    "y_test = data_orig_test.labels.ravel()\n",
    "num_estimators = 100\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=1)\n",
    "\n",
    "mdl = model.fit(X_train, y_train)\n",
    "with open('../../Results/AdaBoost/' + nb_fname + '.pkl', 'wb') as f:\n",
    "        pickle.dump(mdl, f)\n",
    "\n",
    "with open('../../Results/AdaBoost/' + nb_fname + '_Train' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_train, f) \n",
    "    \n",
    "with open('../../Results/AdaBoost/' + nb_fname + '_Test' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(data_orig_test, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "STD [3.02765035 0.06749158 0.08874808 0.09476216 0.03541161 0.01255178]\n",
      "[4.5, -0.6693072547146794, -0.581259725046272, 0.49612085216852686, -2.1276205667545494, 0.1590111172017386]\n",
      "-2.7230555771452356\n",
      "0.8093283582089552\n",
      "0.7401892992453725\n"
     ]
    }
   ],
   "source": [
    "final_metrics = []\n",
    "accuracy = []\n",
    "f1= []\n",
    "from statistics import mean\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    \n",
    "    data_orig_train, data_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "    print(i)\n",
    "    X_train = data_orig_train.features\n",
    "    y_train = data_orig_train.labels.ravel()\n",
    "\n",
    "    X_test = data_orig_test.features\n",
    "    y_test = data_orig_test.labels.ravel()\n",
    "    model = GradientBoostingClassifier(n_estimators = 200)\n",
    "  \n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    fair_list.insert(0, i)\n",
    "    final_metrics.append(fair_list)\n",
    "\n",
    "    \n",
    "element_wise_std =  np.std(final_metrics, 0, ddof=1)\n",
    "print(\"STD \" + str(element_wise_std))\n",
    "final_metrics = list(map(mean, zip(*final_metrics)))\n",
    "accuracy = mean(accuracy)\n",
    "f1 = mean(f1)\n",
    "final_metrics[4] = np.log(final_metrics[4])\n",
    "print(final_metrics)\n",
    "print(sum(final_metrics[1:]))\n",
    "print(accuracy)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "final_metrics = []\n",
    "accuracy = []\n",
    "f1= []\n",
    "\n",
    "for i in range(1,num_estimators+1):\n",
    "    \n",
    "    model = AdaBoostClassifier(n_estimators=i)\n",
    "    \n",
    "    mdl = model.fit(X_train, y_train)\n",
    "    yy = mdl.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, yy))\n",
    "    f1.append(f1_score(y_test, yy))\n",
    "    fair = get_fair_metrics_and_plot(data_orig_test, mdl)                           \n",
    "    fair_list = fair.iloc[1].tolist()\n",
    "    fair_list.insert(0, i)\n",
    "    final_metrics.append(fair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>...</th>\n",
       "      <th>T90</th>\n",
       "      <th>T91</th>\n",
       "      <th>T92</th>\n",
       "      <th>T93</th>\n",
       "      <th>T94</th>\n",
       "      <th>T95</th>\n",
       "      <th>T96</th>\n",
       "      <th>T97</th>\n",
       "      <th>T98</th>\n",
       "      <th>T99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.787313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729614</td>\n",
       "      <td>0.729614</td>\n",
       "      <td>0.735426</td>\n",
       "      <td>0.621469</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.730594</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.729858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical_parity_difference</th>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.867052</td>\n",
       "      <td>-0.867052</td>\n",
       "      <td>-0.908549</td>\n",
       "      <td>-0.489565</td>\n",
       "      <td>-0.578096</td>\n",
       "      <td>-0.947977</td>\n",
       "      <td>-0.708549</td>\n",
       "      <td>-0.799574</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>-0.814846</td>\n",
       "      <td>-0.793794</td>\n",
       "      <td>-0.814846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal_opportunity_difference</th>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.731707</td>\n",
       "      <td>-0.731707</td>\n",
       "      <td>-0.766974</td>\n",
       "      <td>-0.477917</td>\n",
       "      <td>-0.531641</td>\n",
       "      <td>-0.853659</td>\n",
       "      <td>-0.759064</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.775214</td>\n",
       "      <td>-0.761701</td>\n",
       "      <td>-0.775214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_abs_odds_difference</th>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.820399</td>\n",
       "      <td>0.820399</td>\n",
       "      <td>0.864548</td>\n",
       "      <td>0.322833</td>\n",
       "      <td>0.370799</td>\n",
       "      <td>0.915466</td>\n",
       "      <td>0.539705</td>\n",
       "      <td>0.675223</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>0.702001</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>0.702001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disparate_impact</th>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.017797</td>\n",
       "      <td>-2.017797</td>\n",
       "      <td>-2.503652</td>\n",
       "      <td>-2.248073</td>\n",
       "      <td>-1.713065</td>\n",
       "      <td>-2.956067</td>\n",
       "      <td>-2.277845</td>\n",
       "      <td>-2.608239</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>-2.545325</td>\n",
       "      <td>-2.521227</td>\n",
       "      <td>-2.545325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theil_index</th>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.157679</td>\n",
       "      <td>0.157679</td>\n",
       "      <td>0.164565</td>\n",
       "      <td>0.265484</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.171370</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.181456</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>0.179316</td>\n",
       "      <td>0.182624</td>\n",
       "      <td>0.179316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows  101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               classifier        T0        T1        T2  \\\n",
       "accuracy                         0.787313  0.764925  0.764925  0.779851   \n",
       "f1                               0.729858  0.729614  0.729614  0.735426   \n",
       "statistical_parity_difference   -0.814846 -0.867052 -0.867052 -0.908549   \n",
       "equal_opportunity_difference    -0.775214 -0.731707 -0.731707 -0.766974   \n",
       "average_abs_odds_difference      0.702001  0.820399  0.820399  0.864548   \n",
       "disparate_impact                -2.545325 -2.017797 -2.017797 -2.503652   \n",
       "theil_index                      0.179316  0.157679  0.157679  0.164565   \n",
       "\n",
       "                                     T3        T4        T5        T6  \\\n",
       "accuracy                       0.750000  0.783582  0.779851  0.783582   \n",
       "f1                             0.621469  0.715686  0.730594  0.715686   \n",
       "statistical_parity_difference -0.489565 -0.578096 -0.947977 -0.708549   \n",
       "equal_opportunity_difference  -0.477917 -0.531641 -0.853659 -0.759064   \n",
       "average_abs_odds_difference    0.322833  0.370799  0.915466  0.539705   \n",
       "disparate_impact              -2.248073 -1.713065 -2.956067 -2.277845   \n",
       "theil_index                    0.265484  0.193705  0.171370  0.193705   \n",
       "\n",
       "                                     T7        T8  ...       T90       T91  \\\n",
       "accuracy                       0.791045  0.787313  ...  0.787313  0.787313   \n",
       "f1                             0.730769  0.727273  ...  0.729858  0.729858   \n",
       "statistical_parity_difference -0.799574 -0.793794  ... -0.814846 -0.814846   \n",
       "equal_opportunity_difference  -0.761701 -0.761701  ... -0.775214 -0.775214   \n",
       "average_abs_odds_difference    0.675223  0.671435  ...  0.702001  0.702001   \n",
       "disparate_impact              -2.608239 -2.521227  ... -2.545325 -2.545325   \n",
       "theil_index                    0.181456  0.182624  ...  0.179316  0.179316   \n",
       "\n",
       "                                    T92       T93       T94       T95  \\\n",
       "accuracy                       0.787313  0.787313  0.787313  0.787313   \n",
       "f1                             0.729858  0.727273  0.729858  0.729858   \n",
       "statistical_parity_difference -0.814846 -0.793794 -0.814846 -0.814846   \n",
       "equal_opportunity_difference  -0.775214 -0.761701 -0.775214 -0.775214   \n",
       "average_abs_odds_difference    0.702001  0.671435  0.702001  0.702001   \n",
       "disparate_impact              -2.545325 -2.521227 -2.545325 -2.545325   \n",
       "theil_index                    0.179316  0.182624  0.179316  0.179316   \n",
       "\n",
       "                                    T96       T97       T98       T99  \n",
       "accuracy                       0.787313  0.787313  0.787313  0.787313  \n",
       "f1                             0.727273  0.729858  0.727273  0.729858  \n",
       "statistical_parity_difference -0.793794 -0.814846 -0.793794 -0.814846  \n",
       "equal_opportunity_difference  -0.761701 -0.775214 -0.761701 -0.775214  \n",
       "average_abs_odds_difference    0.671435  0.702001  0.671435  0.702001  \n",
       "disparate_impact              -2.521227 -2.545325 -2.521227 -2.545325  \n",
       "theil_index                    0.182624  0.179316  0.182624  0.179316  \n",
       "\n",
       "[7 rows x 101 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "final_result = pd.DataFrame(final_metrics)\n",
    "final_result[4] = np.log(final_result[4])\n",
    "final_result = final_result.transpose()\n",
    "final_result.loc[0] = f1  # add f1 and acc to df\n",
    "acc = pd.DataFrame(accuracy).transpose()\n",
    "acc = acc.rename(index={0: 'accuracy'})\n",
    "final_result = pd.concat([acc,final_result])\n",
    "final_result = final_result.rename(index={0: 'f1', 1: 'statistical_parity_difference', 2: 'equal_opportunity_difference', 3: 'average_abs_odds_difference', 4: 'disparate_impact', 5: 'theil_index'})\n",
    "final_result.columns = ['T' + str(col) for col in final_result.columns]\n",
    "final_result.insert(0, \"classifier\", final_result['T' + str(num_estimators - 1)])   ##Add final metrics add the beginning of the df\n",
    "final_result.to_csv('../../Results/AdaBoost/' + nb_fname + '.csv')\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
